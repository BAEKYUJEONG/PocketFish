{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras 2.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense, BatchNormalization\n",
    "from keras.layers import Flatten, Conv2D, MaxPool2D, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import load_model\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "\n",
    "from random import shuffle\n",
    "from glob import glob\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "import json\n",
    "import base64\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['carpfish', 'rockfish', 'golden mandarin fish', 'red snapper', 'flatfish']\n",
    "img_height = 112\n",
    "img_width = 112\n",
    "\n",
    "# load model\n",
    "model_path = \"./image/test_model2.h5\"\n",
    "pred_model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/', methods=['POST'])\n",
    "def predict():\n",
    "    if request.method == 'POST':\n",
    "        # string으로 이미지 받아오기\n",
    "        # ex) (echo -n '{\"file\": \"'; base64 1.JPG; echo '\"}') | curl -X POST -H \"Content-Type: application/json\" -d @-  http://skeldtcan.iptime.org:5000\n",
    "        file = request.json['file']\n",
    "        image_bytes = base64.b64decode(file)\n",
    "\n",
    "        # 분류 결과 확인 및 클라이언트에게 결과 반환\n",
    "        class_name = Dataization(image_bytes, img_width, img_height)\n",
    "        \n",
    "        # 내림차순 정렬\n",
    "        result = \"{\"\n",
    "        for k, v in class_name.items():\n",
    "            if v == 0:\n",
    "                break\n",
    "            result += f\"'{k}':{v},\"\n",
    "        result = result[:-1] + \"}\"\n",
    "        \n",
    "        print(class_name)\n",
    "        print(result)\n",
    "        return json.dumps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dataization(image_bytes, img_w, img_h):\n",
    "    # 이미지 저장\n",
    "    img = Image.open(io.BytesIO(image_bytes))\n",
    "    img = img.convert(\"RGB\")\n",
    "    img = img.resize((img_w, img_h))\n",
    "    img_data = np.asarray(img)\n",
    "    pred_data = [img_data/255]\n",
    "    pred_data = np.array(pred_data)\n",
    "\n",
    "    # predict\n",
    "    pred_result = pred_model.predict(pred_data)[0]\n",
    "    pred_result = list(pred_result)\n",
    "    result_percentage = [round(p*100,3) for p in pred_result]\n",
    "    \n",
    "    # save dict\n",
    "    fish = collections.OrderedDict()\n",
    "    for k, v in zip(class_names, result_percentage):\n",
    "        fish[k] = v\n",
    "\n",
    "    fish = collections.OrderedDict(sorted(fish.items(), key=lambda x: -x[1]))\n",
    "    \n",
    "    return fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "# 최대 50MB\n",
    "app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024 \n",
    "# 모든 호스트에 대해 접속 허용\n",
    "app.run(threaded=False, host='0.0.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hong",
   "language": "python",
   "name": "hong"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
