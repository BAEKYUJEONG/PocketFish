{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoQQiZDB6URn",
    "tags": []
   },
   "source": [
    "## 물고기 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3vhAMaIOBIee",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA error 잡기\n",
    "- TF와 내부 CUDA 버전 안 맞을 때 에러 나는 경우가 많음\n",
    "- 해당 문제를 해결하기 위해 아래의 버전 맞추기 코드를 붙여넣자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 불러오기\n",
    "- 현재 디렉토리의 위치를 기준으로 데이터가 있는 path를 지정해준다\n",
    "- 맞는 path인지 확인하기 위해 데이터의 전체 갯수를 세서 리턴한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QhewYCxhXQBX",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of data: 396\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 불러오기\n",
    "data_dir = pathlib.Path('./dataset')\n",
    "image_count = len(list(data_dir.glob('*/*.jpg'))) + len(list(data_dir.glob('*/*.jpeg'))) + len(list(data_dir.glob('*/*.png')))\n",
    "\n",
    "print(f'total number of data: {image_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qJdpyqK541ty",
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "img_height = 112\n",
    "img_width = 112"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras.preprocessing = 디스크의 이미지 디렉토리를 `tf.data.Dataset`으로 가져옴\n",
    "= 그냥 이미지 로드해주는 애\n",
    "\n",
    "검증 분할 = training:validation 비율을 8:2로 정해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "chqakIP14PDm",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 396 files belonging to 6 classes.\n",
      "Using 278 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.3,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pb2Af2lsUShk",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 396 files belonging to 6 classes.\n",
      "Using 118 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.3,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ug3ITsz0b_cF"
   },
   "source": [
    "이러한 데이터세트의 `class_names` 속성에서 클래스 이름을 찾을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "R7z2yKt7VDPJ",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['catfish_메기', 'crucian carp_붕어', 'flatfish_광어', 'golden mandarin fish_쏘가리', 'red snapper_참돔', 'rockfish_우럭']\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(class_names)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BdPHeHXt9sjA",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 112, 112, 3)\n",
      "(16,)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZgIZeXaDUsF"
   },
   "source": [
    "`image_batch`는 형상 `(32, 180, 180, 3)`의 텐서입니다. 이것은 형상 `180x180x3`의 32개 이미지 배치입니다(마지막 치수는 색상 채널 RGB를 나타냄). `label_batch`는 형상 `(32,)`의 텐서이며 32개 이미지에 해당하는 레이블입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyM2y47W-cxJ"
   },
   "source": [
    "참고: 이들 텐서 중 하나에서 `.numpy()`를 호출하여 `numpy.ndarray`로 변환할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[int(labels[i])][:len(class_names[int(labels[i])]) - 3])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in val_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[int(labels[i])][:len(class_names[int(labels[i])]) - 3])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ybl6a2YCg1rV"
   },
   "source": [
    "### 데이터 표준화하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdogGjM2K6OU"
   },
   "source": [
    "RGB 채널 값은 `[0, 255]` 범위에 있습니다. 신경망에는 이상적이지 않습니다. 일반적으로 입력 값을 작게 만들어야 합니다. 여기서는 Rescaling 레이어를 사용하여 값이 `[0, 1]`에 있도록 표준화합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16yNdZXdExyM",
    "tags": []
   },
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE),\n",
    "    layers.experimental.preprocessing.Rescaling(1./255)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nd0_enkb8uxZ"
   },
   "source": [
    "이 레이어를 사용하는 방법에는 두 가지가 있습니다. map을 호출하여 데이터세트에 레이어를 적용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgOnza-U_z5Y",
    "tags": []
   },
   "source": [
    "# data_augmentation = tf.keras.Sequential([\n",
    "#     layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "#     layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z39nXayj9ioS"
   },
   "source": [
    "또는 모델 정의 내에 레이어를 포함하여 배포를 단순화할 수 있습니다. 여기서는 두 번째 접근 방식을 사용할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXLd3wMpDIkp"
   },
   "source": [
    "참고: 픽셀 값을 `[-1,1]`으로 조정하려면 대신 `Rescaling(1./127.5, offset=-1)`를 작성할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LeNWVa8qRBGm"
   },
   "source": [
    "참고: 이전에 `image_dataset_from_directory`의 `image_size` 인수를 사용하여 이미지 크기를 조정했습니다. 모델에 크기 조정 논리를 포함하려면 [Resizing](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Resizing) 레이어를 대신 사용할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ti8avTlLofoJ"
   },
   "source": [
    "### 성능을 위한 데이터세트 구성하기\n",
    "\n",
    "버퍼링된 프리페치를 사용하여 I/O가 차단되지 않고 디스크에서 데이터를 생성할 수 있도록 합니다. 데이터를 로드할 때 사용해야 하는 두 가지 중요한 메서드입니다.\n",
    "\n",
    "`.cache()`는 첫 번째 epoch 동안 디스크에서 이미지를 로드한 후 이미지를 메모리에 유지합니다. 이렇게 하면 모델을 훈련하는 동안 데이터세트가 병목 상태가 되지 않습니다. 데이터세트가 너무 커서 메모리에 맞지 않는 경우, 이 메서드를 사용하여 성능이 높은 온디스크 캐시를 생성할 수도 있습니다.\n",
    "\n",
    "`.prefetch()`는 훈련 중에 데이터 전처리 및 모델 실행과 겹칩니다.\n",
    "\n",
    "관심 있는 독자는 [데이터 성능 가이드](https://www.tensorflow.org/guide/data_performance#prefetching)에서 두 가지 메서드와 디스크에 데이터를 캐시하는 방법에 대해 자세히 알아볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ea3kbMe-pGDw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "# image_batch, labels_batch = next(iter(normalized_ds))\n",
    "# first_image = image_batch[0]\n",
    "# # Notice the pixels values are now in `[0,1]`.\n",
    "# print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqHjIr6cplwY"
   },
   "source": [
    "### 모델 훈련하기\n",
    "\n",
    "완전성을 위해 준비한 데이터세트를 사용하여 간단한 모델을 훈련하는 방법을 보여줍니다. 이 모델은 어떤 식으로든 조정되지 않았습니다. 목표는 방금 만든 데이터세트를 사용하여 역학을 보여주는 것입니다. 이미지 분류에 대한 자세한 내용은 이 [튜토리얼](https://www.tensorflow.org/tutorials/images/classification)을 참조하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LdR0BzCcqxw0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#     resize_and_rescale,\n",
    "# #     data_augmentation,\n",
    "#     layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "    \n",
    "#     layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "    \n",
    "#     layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "    \n",
    "#     layers.Dropout(0.2),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(128, activation='relu'),\n",
    "#     layers.Dense(num_classes, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling (Rescaling)        (None, 112, 112, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 112, 112, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 56, 56, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 30,382,662\n",
      "Trainable params: 30,382,662\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# 224x224 RGB images as input\n",
    "model.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)))\n",
    "# model.add(tf.keras.Input(shape=(img_height, img_width, 3)))\n",
    "\n",
    "# adding layers\n",
    "# batch normalization, dropout = overfitting 방지rfitting 방지\n",
    "model.add(layers.Conv2D(64, 3, strides = (1,1), padding='same', activation='relu'))\n",
    "model.add(layers.Conv2D(64, 3, strides = (1,1), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, 3, strides = (1,1), padding='same', activation='relu'))\n",
    "model.add(layers.Conv2D(128, 3, strides = (1,1), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(256, 3, strides = (1,1), padding='same', activation='relu'))\n",
    "model.add(layers.Conv2D(256, 3, strides = (1,1), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(512, 3, strides = (1,1), padding='same', activation='relu'))\n",
    "model.add(layers.Conv2D(512, 3, strides = (1,1), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 2차원의 그림을 1차원을 바꿔준다\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# 입력계층의 갯수 정하기\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "# 가진 클래스의 갯수만큼 출력층 만들어주기\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "t_BlmsnmsEr4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.00001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffwd44ldNMOE"
   },
   "source": [
    "참고: 몇 가지 epoch에 대해서만 훈련하므로 이 튜토리얼은 빠르게 진행됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "S08ZKKODsnGW",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 8s 192ms/step - loss: 1.7899 - accuracy: 0.2124 - val_loss: 1.7825 - val_accuracy: 0.3051\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 1.7708 - accuracy: 0.3341 - val_loss: 1.7798 - val_accuracy: 0.2203\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 2s 91ms/step - loss: 1.7498 - accuracy: 0.3078 - val_loss: 1.7712 - val_accuracy: 0.2034\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 2s 90ms/step - loss: 1.7129 - accuracy: 0.2893 - val_loss: 1.7214 - val_accuracy: 0.2542\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 2s 91ms/step - loss: 1.6320 - accuracy: 0.3500 - val_loss: 1.6221 - val_accuracy: 0.3220\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 2s 91ms/step - loss: 1.5120 - accuracy: 0.3936 - val_loss: 1.5561 - val_accuracy: 0.3475\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 2s 91ms/step - loss: 1.4309 - accuracy: 0.4311 - val_loss: 1.5194 - val_accuracy: 0.3220\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 2s 91ms/step - loss: 1.3807 - accuracy: 0.4280 - val_loss: 1.4825 - val_accuracy: 0.3559\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 1.3225 - accuracy: 0.4970 - val_loss: 1.4740 - val_accuracy: 0.3390\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.2632 - accuracy: 0.5360 - val_loss: 1.4605 - val_accuracy: 0.3559\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 1.2096 - accuracy: 0.5752 - val_loss: 1.4282 - val_accuracy: 0.3814\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 1.1520 - accuracy: 0.5800 - val_loss: 1.3978 - val_accuracy: 0.3729\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 1.0861 - accuracy: 0.6288 - val_loss: 1.3717 - val_accuracy: 0.4407\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 1.0164 - accuracy: 0.6657 - val_loss: 1.3397 - val_accuracy: 0.4576\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 0.9456 - accuracy: 0.6874 - val_loss: 1.3104 - val_accuracy: 0.4746\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 0.8684 - accuracy: 0.7071 - val_loss: 1.2931 - val_accuracy: 0.4746\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 0.7870 - accuracy: 0.7290 - val_loss: 1.2950 - val_accuracy: 0.4746\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 0.7015 - accuracy: 0.7912 - val_loss: 1.3041 - val_accuracy: 0.4915\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.6204 - accuracy: 0.8157 - val_loss: 1.3025 - val_accuracy: 0.4915\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.5469 - accuracy: 0.8393 - val_loss: 1.3127 - val_accuracy: 0.4831\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.4855 - accuracy: 0.8490 - val_loss: 1.3097 - val_accuracy: 0.5254\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 0.4316 - accuracy: 0.8541 - val_loss: 1.3499 - val_accuracy: 0.5508\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.3880 - accuracy: 0.8958 - val_loss: 1.4889 - val_accuracy: 0.5424\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 0.3632 - accuracy: 0.9058 - val_loss: 1.8256 - val_accuracy: 0.5169\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.3812 - accuracy: 0.8807 - val_loss: 1.6293 - val_accuracy: 0.5424\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.3372 - accuracy: 0.9242 - val_loss: 1.4324 - val_accuracy: 0.5763\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.2677 - accuracy: 0.9509 - val_loss: 1.2686 - val_accuracy: 0.5932\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.1919 - accuracy: 0.9594 - val_loss: 1.3049 - val_accuracy: 0.6186\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.1527 - accuracy: 0.9727 - val_loss: 1.3634 - val_accuracy: 0.6271\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 0.1332 - accuracy: 0.9777 - val_loss: 1.4610 - val_accuracy: 0.6186\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 0.1189 - accuracy: 0.9777 - val_loss: 1.5298 - val_accuracy: 0.6186\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.1047 - accuracy: 0.9859 - val_loss: 1.6272 - val_accuracy: 0.6102\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.0949 - accuracy: 0.9791 - val_loss: 1.6461 - val_accuracy: 0.6271\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.0835 - accuracy: 0.9975 - val_loss: 1.6526 - val_accuracy: 0.6017\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.0796 - accuracy: 0.9975 - val_loss: 1.6008 - val_accuracy: 0.6017\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.0794 - accuracy: 0.9975 - val_loss: 1.5052 - val_accuracy: 0.6271\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.0847 - accuracy: 0.9876 - val_loss: 1.4383 - val_accuracy: 0.6695\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 0.1090 - accuracy: 0.9825 - val_loss: 1.3837 - val_accuracy: 0.6780\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.1829 - accuracy: 0.9385 - val_loss: 1.6339 - val_accuracy: 0.6271\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 0.3994 - accuracy: 0.8622 - val_loss: 1.4172 - val_accuracy: 0.6356\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.3069 - accuracy: 0.8871 - val_loss: 1.2522 - val_accuracy: 0.6610\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 0.0818 - accuracy: 0.9922 - val_loss: 1.1464 - val_accuracy: 0.7034\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.0553 - accuracy: 0.9985 - val_loss: 1.2544 - val_accuracy: 0.6695\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 1.3873 - val_accuracy: 0.6610\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 1.4012 - val_accuracy: 0.6610\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 1.3610 - val_accuracy: 0.6864\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.3930 - val_accuracy: 0.6780\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.4317 - val_accuracy: 0.6780\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.4533 - val_accuracy: 0.6864\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 2s 102ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.4779 - val_accuracy: 0.6864\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 2s 112ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.5016 - val_accuracy: 0.6864\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 2s 104ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.5217 - val_accuracy: 0.6864\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.5428 - val_accuracy: 0.6949\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 2s 101ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.5620 - val_accuracy: 0.6949\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 2s 103ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.5813 - val_accuracy: 0.6949\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 2s 104ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.5985 - val_accuracy: 0.6949\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 2s 107ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.6161 - val_accuracy: 0.6949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000\n",
      "18/18 [==============================] - 2s 104ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.6318 - val_accuracy: 0.6949\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 2s 105ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.6485 - val_accuracy: 0.6949\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 2s 109ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.6634 - val_accuracy: 0.6949\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 2s 107ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.6788 - val_accuracy: 0.6949\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 2s 104ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.6937 - val_accuracy: 0.6949\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.7073 - val_accuracy: 0.6949\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.7214 - val_accuracy: 0.6949\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.7344 - val_accuracy: 0.6949\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.7463 - val_accuracy: 0.7034\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.7598 - val_accuracy: 0.7034\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.7717 - val_accuracy: 0.7034\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.7834 - val_accuracy: 0.7034\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.7949 - val_accuracy: 0.7034\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.8053 - val_accuracy: 0.7034\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.8159 - val_accuracy: 0.7034\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.8270 - val_accuracy: 0.7034\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.8375 - val_accuracy: 0.7034\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.8481 - val_accuracy: 0.7034\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.8578 - val_accuracy: 0.7034\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.8682 - val_accuracy: 0.7034\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.8772 - val_accuracy: 0.7034\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.8873 - val_accuracy: 0.7034\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.8960 - val_accuracy: 0.7034\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9048 - val_accuracy: 0.7034\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9136 - val_accuracy: 0.7034\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.9224 - val_accuracy: 0.7034\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.9311 - val_accuracy: 0.7034\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9403 - val_accuracy: 0.7034\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9481 - val_accuracy: 0.7034\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.9570 - val_accuracy: 0.7034\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.9648 - val_accuracy: 0.7034\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.9732 - val_accuracy: 0.7034\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.9806 - val_accuracy: 0.6949\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.9884 - val_accuracy: 0.6949\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.9957 - val_accuracy: 0.6949\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 9.8347e-04 - accuracy: 1.0000 - val_loss: 2.0036 - val_accuracy: 0.6949\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 9.5128e-04 - accuracy: 1.0000 - val_loss: 2.0111 - val_accuracy: 0.6949\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 9.2059e-04 - accuracy: 1.0000 - val_loss: 2.0183 - val_accuracy: 0.6949\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 8.9159e-04 - accuracy: 1.0000 - val_loss: 2.0254 - val_accuracy: 0.6864\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 8.6209e-04 - accuracy: 1.0000 - val_loss: 2.0332 - val_accuracy: 0.6864\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 8.3543e-04 - accuracy: 1.0000 - val_loss: 2.0390 - val_accuracy: 0.6949\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 8.0977e-04 - accuracy: 1.0000 - val_loss: 2.0470 - val_accuracy: 0.6949\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 7.8374e-04 - accuracy: 1.0000 - val_loss: 2.0538 - val_accuracy: 0.6949\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 7.5966e-04 - accuracy: 1.0000 - val_loss: 2.0611 - val_accuracy: 0.6949\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 7.3725e-04 - accuracy: 1.0000 - val_loss: 2.0678 - val_accuracy: 0.6949\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 2s 102ms/step - loss: 7.1476e-04 - accuracy: 1.0000 - val_loss: 2.0748 - val_accuracy: 0.6949\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 6.9381e-04 - accuracy: 1.0000 - val_loss: 2.0816 - val_accuracy: 0.6949\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 2s 102ms/step - loss: 6.7259e-04 - accuracy: 1.0000 - val_loss: 2.0883 - val_accuracy: 0.6949\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 2s 105ms/step - loss: 6.5413e-04 - accuracy: 1.0000 - val_loss: 2.0945 - val_accuracy: 0.6949\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 6.3458e-04 - accuracy: 1.0000 - val_loss: 2.1011 - val_accuracy: 0.6949\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 6.1717e-04 - accuracy: 1.0000 - val_loss: 2.1078 - val_accuracy: 0.6949\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 5.9928e-04 - accuracy: 1.0000 - val_loss: 2.1148 - val_accuracy: 0.6949\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 5.8272e-04 - accuracy: 1.0000 - val_loss: 2.1207 - val_accuracy: 0.6949\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 5.6621e-04 - accuracy: 1.0000 - val_loss: 2.1274 - val_accuracy: 0.6949\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 5.5087e-04 - accuracy: 1.0000 - val_loss: 2.1339 - val_accuracy: 0.6949\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 5.3544e-04 - accuracy: 1.0000 - val_loss: 2.1396 - val_accuracy: 0.6949\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 5.2169e-04 - accuracy: 1.0000 - val_loss: 2.1461 - val_accuracy: 0.6949\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 5.0658e-04 - accuracy: 1.0000 - val_loss: 2.1519 - val_accuracy: 0.6949\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.9388e-04 - accuracy: 1.0000 - val_loss: 2.1585 - val_accuracy: 0.6949\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.7982e-04 - accuracy: 1.0000 - val_loss: 2.1643 - val_accuracy: 0.6949\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 4.6788e-04 - accuracy: 1.0000 - val_loss: 2.1706 - val_accuracy: 0.6949\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 4.5505e-04 - accuracy: 1.0000 - val_loss: 2.1762 - val_accuracy: 0.6949\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 4.4360e-04 - accuracy: 1.0000 - val_loss: 2.1822 - val_accuracy: 0.6949\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 4.3155e-04 - accuracy: 1.0000 - val_loss: 2.1884 - val_accuracy: 0.6949\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.2073e-04 - accuracy: 1.0000 - val_loss: 2.1936 - val_accuracy: 0.6949\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 4.0957e-04 - accuracy: 1.0000 - val_loss: 2.2000 - val_accuracy: 0.6949\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.9933e-04 - accuracy: 1.0000 - val_loss: 2.2056 - val_accuracy: 0.6949\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 3.8896e-04 - accuracy: 1.0000 - val_loss: 2.2111 - val_accuracy: 0.6949\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 3.7924e-04 - accuracy: 1.0000 - val_loss: 2.2170 - val_accuracy: 0.6949\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.6958e-04 - accuracy: 1.0000 - val_loss: 2.2223 - val_accuracy: 0.6949\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 3.6048e-04 - accuracy: 1.0000 - val_loss: 2.2283 - val_accuracy: 0.6949\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.5147e-04 - accuracy: 1.0000 - val_loss: 2.2339 - val_accuracy: 0.6949\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 3.4312e-04 - accuracy: 1.0000 - val_loss: 2.2394 - val_accuracy: 0.6949\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.3449e-04 - accuracy: 1.0000 - val_loss: 2.2448 - val_accuracy: 0.6949\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 3.2683e-04 - accuracy: 1.0000 - val_loss: 2.2498 - val_accuracy: 0.6949\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.1864e-04 - accuracy: 1.0000 - val_loss: 2.2556 - val_accuracy: 0.6949\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.1139e-04 - accuracy: 1.0000 - val_loss: 2.2608 - val_accuracy: 0.6949\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.0374e-04 - accuracy: 1.0000 - val_loss: 2.2659 - val_accuracy: 0.6949\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 2.9688e-04 - accuracy: 1.0000 - val_loss: 2.2712 - val_accuracy: 0.6949\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 2.8977e-04 - accuracy: 1.0000 - val_loss: 2.2762 - val_accuracy: 0.6949\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 2.8308e-04 - accuracy: 1.0000 - val_loss: 2.2814 - val_accuracy: 0.7034\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 2.7668e-04 - accuracy: 1.0000 - val_loss: 2.2862 - val_accuracy: 0.7034\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 2.7041e-04 - accuracy: 1.0000 - val_loss: 2.2912 - val_accuracy: 0.7034\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 2.6412e-04 - accuracy: 1.0000 - val_loss: 2.2966 - val_accuracy: 0.7034\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 2.5829e-04 - accuracy: 1.0000 - val_loss: 2.3014 - val_accuracy: 0.7034\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 2.5247e-04 - accuracy: 1.0000 - val_loss: 2.3066 - val_accuracy: 0.7034\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 2.4693e-04 - accuracy: 1.0000 - val_loss: 2.3116 - val_accuracy: 0.7034\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 2.4131e-04 - accuracy: 1.0000 - val_loss: 2.3162 - val_accuracy: 0.7034\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 2.3608e-04 - accuracy: 1.0000 - val_loss: 2.3214 - val_accuracy: 0.7034\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 2.3084e-04 - accuracy: 1.0000 - val_loss: 2.3261 - val_accuracy: 0.7034\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.2575e-04 - accuracy: 1.0000 - val_loss: 2.3311 - val_accuracy: 0.7034\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 2.2092e-04 - accuracy: 1.0000 - val_loss: 2.3363 - val_accuracy: 0.7034\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 2.1613e-04 - accuracy: 1.0000 - val_loss: 2.3410 - val_accuracy: 0.7034\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 2.1145e-04 - accuracy: 1.0000 - val_loss: 2.3457 - val_accuracy: 0.6949\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 2.0700e-04 - accuracy: 1.0000 - val_loss: 2.3510 - val_accuracy: 0.6949\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 2.0255e-04 - accuracy: 1.0000 - val_loss: 2.3557 - val_accuracy: 0.6949\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 1.9827e-04 - accuracy: 1.0000 - val_loss: 2.3606 - val_accuracy: 0.6949\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.9408e-04 - accuracy: 1.0000 - val_loss: 2.3654 - val_accuracy: 0.6949\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.9001e-04 - accuracy: 1.0000 - val_loss: 2.3700 - val_accuracy: 0.6949\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 1.8616e-04 - accuracy: 1.0000 - val_loss: 2.3752 - val_accuracy: 0.6949\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.8211e-04 - accuracy: 1.0000 - val_loss: 2.3800 - val_accuracy: 0.6949\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 1.7858e-04 - accuracy: 1.0000 - val_loss: 2.3846 - val_accuracy: 0.6949\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.7472e-04 - accuracy: 1.0000 - val_loss: 2.3893 - val_accuracy: 0.6949\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 1.7123e-04 - accuracy: 1.0000 - val_loss: 2.3942 - val_accuracy: 0.6949\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 1.6764e-04 - accuracy: 1.0000 - val_loss: 2.3990 - val_accuracy: 0.6949\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.6435e-04 - accuracy: 1.0000 - val_loss: 2.4034 - val_accuracy: 0.6949\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.6096e-04 - accuracy: 1.0000 - val_loss: 2.4081 - val_accuracy: 0.6949\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 1.5773e-04 - accuracy: 1.0000 - val_loss: 2.4130 - val_accuracy: 0.6949\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 1.5450e-04 - accuracy: 1.0000 - val_loss: 2.4175 - val_accuracy: 0.6949\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.5150e-04 - accuracy: 1.0000 - val_loss: 2.4222 - val_accuracy: 0.6949\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 1.4844e-04 - accuracy: 1.0000 - val_loss: 2.4267 - val_accuracy: 0.6949\n",
      "Epoch 169/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 95ms/step - loss: 1.4550e-04 - accuracy: 1.0000 - val_loss: 2.4314 - val_accuracy: 0.6949\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 1.4268e-04 - accuracy: 1.0000 - val_loss: 2.4358 - val_accuracy: 0.6949\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 1.3987e-04 - accuracy: 1.0000 - val_loss: 2.4403 - val_accuracy: 0.6949\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.3715e-04 - accuracy: 1.0000 - val_loss: 2.4449 - val_accuracy: 0.6949\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 1.3442e-04 - accuracy: 1.0000 - val_loss: 2.4494 - val_accuracy: 0.6864\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 1.3189e-04 - accuracy: 1.0000 - val_loss: 2.4539 - val_accuracy: 0.6864\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 1.2933e-04 - accuracy: 1.0000 - val_loss: 2.4581 - val_accuracy: 0.6864\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 1.2683e-04 - accuracy: 1.0000 - val_loss: 2.4629 - val_accuracy: 0.6949\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.2443e-04 - accuracy: 1.0000 - val_loss: 2.4673 - val_accuracy: 0.6949\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.2200e-04 - accuracy: 1.0000 - val_loss: 2.4717 - val_accuracy: 0.6949\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 1.1972e-04 - accuracy: 1.0000 - val_loss: 2.4762 - val_accuracy: 0.6949\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.1748e-04 - accuracy: 1.0000 - val_loss: 2.4806 - val_accuracy: 0.6949\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 1.1522e-04 - accuracy: 1.0000 - val_loss: 2.4847 - val_accuracy: 0.6949\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 1.1304e-04 - accuracy: 1.0000 - val_loss: 2.4894 - val_accuracy: 0.6949\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.1100e-04 - accuracy: 1.0000 - val_loss: 2.4934 - val_accuracy: 0.6949\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 1.0890e-04 - accuracy: 1.0000 - val_loss: 2.4979 - val_accuracy: 0.6949\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 1.0689e-04 - accuracy: 1.0000 - val_loss: 2.5023 - val_accuracy: 0.6949\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.0497e-04 - accuracy: 1.0000 - val_loss: 2.5065 - val_accuracy: 0.6949\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 1.0297e-04 - accuracy: 1.0000 - val_loss: 2.5108 - val_accuracy: 0.6949\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.0110e-04 - accuracy: 1.0000 - val_loss: 2.5153 - val_accuracy: 0.6949\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 9.9280e-05 - accuracy: 1.0000 - val_loss: 2.5195 - val_accuracy: 0.6949\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 9.7427e-05 - accuracy: 1.0000 - val_loss: 2.5236 - val_accuracy: 0.6949\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 9.5699e-05 - accuracy: 1.0000 - val_loss: 2.5282 - val_accuracy: 0.6949\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 9.3910e-05 - accuracy: 1.0000 - val_loss: 2.5322 - val_accuracy: 0.6949\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 9.2288e-05 - accuracy: 1.0000 - val_loss: 2.5368 - val_accuracy: 0.6949\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 9.0562e-05 - accuracy: 1.0000 - val_loss: 2.5409 - val_accuracy: 0.6949\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 8.8977e-05 - accuracy: 1.0000 - val_loss: 2.5451 - val_accuracy: 0.6949\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 8.7409e-05 - accuracy: 1.0000 - val_loss: 2.5493 - val_accuracy: 0.6949\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 8.5839e-05 - accuracy: 1.0000 - val_loss: 2.5535 - val_accuracy: 0.6949\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 8.4312e-05 - accuracy: 1.0000 - val_loss: 2.5578 - val_accuracy: 0.6949\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 8.2875e-05 - accuracy: 1.0000 - val_loss: 2.5617 - val_accuracy: 0.6949\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 8.1387e-05 - accuracy: 1.0000 - val_loss: 2.5661 - val_accuracy: 0.6949\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 7.9964e-05 - accuracy: 1.0000 - val_loss: 2.5702 - val_accuracy: 0.6949\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 7.8599e-05 - accuracy: 1.0000 - val_loss: 2.5744 - val_accuracy: 0.6949\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 7.7235e-05 - accuracy: 1.0000 - val_loss: 2.5788 - val_accuracy: 0.6949\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 7.5877e-05 - accuracy: 1.0000 - val_loss: 2.5827 - val_accuracy: 0.6949\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 7.4607e-05 - accuracy: 1.0000 - val_loss: 2.5868 - val_accuracy: 0.6949\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 7.3289e-05 - accuracy: 1.0000 - val_loss: 2.5912 - val_accuracy: 0.6949\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 7.2078e-05 - accuracy: 1.0000 - val_loss: 2.5950 - val_accuracy: 0.6949\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 7.0796e-05 - accuracy: 1.0000 - val_loss: 2.5990 - val_accuracy: 0.6949\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 6.9646e-05 - accuracy: 1.0000 - val_loss: 2.6034 - val_accuracy: 0.6949\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 6.8441e-05 - accuracy: 1.0000 - val_loss: 2.6072 - val_accuracy: 0.6949\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.7307e-05 - accuracy: 1.0000 - val_loss: 2.6116 - val_accuracy: 0.6949\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 6.6135e-05 - accuracy: 1.0000 - val_loss: 2.6154 - val_accuracy: 0.6949\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.5072e-05 - accuracy: 1.0000 - val_loss: 2.6197 - val_accuracy: 0.6949\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 6.3939e-05 - accuracy: 1.0000 - val_loss: 2.6232 - val_accuracy: 0.6949\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 6.2889e-05 - accuracy: 1.0000 - val_loss: 2.6279 - val_accuracy: 0.6949\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 6.1859e-05 - accuracy: 1.0000 - val_loss: 2.6316 - val_accuracy: 0.6949\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 6.0801e-05 - accuracy: 1.0000 - val_loss: 2.6356 - val_accuracy: 0.6949\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 5.9782e-05 - accuracy: 1.0000 - val_loss: 2.6399 - val_accuracy: 0.6949\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 5.8834e-05 - accuracy: 1.0000 - val_loss: 2.6438 - val_accuracy: 0.6949\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 5.7791e-05 - accuracy: 1.0000 - val_loss: 2.6474 - val_accuracy: 0.6949\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 5.6919e-05 - accuracy: 1.0000 - val_loss: 2.6516 - val_accuracy: 0.6949\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 5.5928e-05 - accuracy: 1.0000 - val_loss: 2.6554 - val_accuracy: 0.6949\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 5.5060e-05 - accuracy: 1.0000 - val_loss: 2.6596 - val_accuracy: 0.6949\n",
      "Epoch 224/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 96ms/step - loss: 5.4118e-05 - accuracy: 1.0000 - val_loss: 2.6635 - val_accuracy: 0.6949\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 5.3261e-05 - accuracy: 1.0000 - val_loss: 2.6676 - val_accuracy: 0.6949\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 5.2396e-05 - accuracy: 1.0000 - val_loss: 2.6713 - val_accuracy: 0.6949\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 5.1546e-05 - accuracy: 1.0000 - val_loss: 2.6758 - val_accuracy: 0.6949\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 5.0689e-05 - accuracy: 1.0000 - val_loss: 2.6794 - val_accuracy: 0.6949\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 4.9921e-05 - accuracy: 1.0000 - val_loss: 2.6834 - val_accuracy: 0.6949\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 4.9055e-05 - accuracy: 1.0000 - val_loss: 2.6874 - val_accuracy: 0.6949\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 4.8313e-05 - accuracy: 1.0000 - val_loss: 2.6915 - val_accuracy: 0.6949\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 4.7519e-05 - accuracy: 1.0000 - val_loss: 2.6954 - val_accuracy: 0.6949\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 2s 103ms/step - loss: 4.6762e-05 - accuracy: 1.0000 - val_loss: 2.6992 - val_accuracy: 0.6949\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 4.6016e-05 - accuracy: 1.0000 - val_loss: 2.7032 - val_accuracy: 0.6949\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 2s 104ms/step - loss: 4.5274e-05 - accuracy: 1.0000 - val_loss: 2.7071 - val_accuracy: 0.6949\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 2s 105ms/step - loss: 4.4571e-05 - accuracy: 1.0000 - val_loss: 2.7109 - val_accuracy: 0.6949\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 2s 103ms/step - loss: 4.3852e-05 - accuracy: 1.0000 - val_loss: 2.7149 - val_accuracy: 0.6949\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 2s 104ms/step - loss: 4.3148e-05 - accuracy: 1.0000 - val_loss: 2.7189 - val_accuracy: 0.6949\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 2s 101ms/step - loss: 4.2499e-05 - accuracy: 1.0000 - val_loss: 2.7227 - val_accuracy: 0.6949\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 2s 102ms/step - loss: 4.1809e-05 - accuracy: 1.0000 - val_loss: 2.7266 - val_accuracy: 0.6949\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 4.1172e-05 - accuracy: 1.0000 - val_loss: 2.7303 - val_accuracy: 0.6949\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.0502e-05 - accuracy: 1.0000 - val_loss: 2.7344 - val_accuracy: 0.6949\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 3.9865e-05 - accuracy: 1.0000 - val_loss: 2.7383 - val_accuracy: 0.6949\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.9251e-05 - accuracy: 1.0000 - val_loss: 2.7421 - val_accuracy: 0.6949\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 3.8654e-05 - accuracy: 1.0000 - val_loss: 2.7458 - val_accuracy: 0.6949\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.8027e-05 - accuracy: 1.0000 - val_loss: 2.7498 - val_accuracy: 0.6949\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 3.7448e-05 - accuracy: 1.0000 - val_loss: 2.7537 - val_accuracy: 0.6949\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.6865e-05 - accuracy: 1.0000 - val_loss: 2.7573 - val_accuracy: 0.6949\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.6303e-05 - accuracy: 1.0000 - val_loss: 2.7614 - val_accuracy: 0.6949\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.5742e-05 - accuracy: 1.0000 - val_loss: 2.7651 - val_accuracy: 0.6949\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.5185e-05 - accuracy: 1.0000 - val_loss: 2.7690 - val_accuracy: 0.6949\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 3.4654e-05 - accuracy: 1.0000 - val_loss: 2.7727 - val_accuracy: 0.6949\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.4113e-05 - accuracy: 1.0000 - val_loss: 2.7767 - val_accuracy: 0.6949\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.3593e-05 - accuracy: 1.0000 - val_loss: 2.7805 - val_accuracy: 0.6949\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.3081e-05 - accuracy: 1.0000 - val_loss: 2.7843 - val_accuracy: 0.6949\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.2556e-05 - accuracy: 1.0000 - val_loss: 2.7880 - val_accuracy: 0.6949\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.2075e-05 - accuracy: 1.0000 - val_loss: 2.7919 - val_accuracy: 0.6949\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 3.1575e-05 - accuracy: 1.0000 - val_loss: 2.7958 - val_accuracy: 0.6949\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.1083e-05 - accuracy: 1.0000 - val_loss: 2.7996 - val_accuracy: 0.6949\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.0617e-05 - accuracy: 1.0000 - val_loss: 2.8033 - val_accuracy: 0.6949\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.0131e-05 - accuracy: 1.0000 - val_loss: 2.8075 - val_accuracy: 0.6949\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.9687e-05 - accuracy: 1.0000 - val_loss: 2.8110 - val_accuracy: 0.6949\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.9212e-05 - accuracy: 1.0000 - val_loss: 2.8150 - val_accuracy: 0.6949\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.8770e-05 - accuracy: 1.0000 - val_loss: 2.8187 - val_accuracy: 0.6949\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.8330e-05 - accuracy: 1.0000 - val_loss: 2.8226 - val_accuracy: 0.6949\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.7914e-05 - accuracy: 1.0000 - val_loss: 2.8260 - val_accuracy: 0.6949\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.7476e-05 - accuracy: 1.0000 - val_loss: 2.8301 - val_accuracy: 0.6949\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.7076e-05 - accuracy: 1.0000 - val_loss: 2.8337 - val_accuracy: 0.6949\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.6668e-05 - accuracy: 1.0000 - val_loss: 2.8374 - val_accuracy: 0.6949\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.6261e-05 - accuracy: 1.0000 - val_loss: 2.8412 - val_accuracy: 0.6949\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.5865e-05 - accuracy: 1.0000 - val_loss: 2.8448 - val_accuracy: 0.6949\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.5484e-05 - accuracy: 1.0000 - val_loss: 2.8483 - val_accuracy: 0.6949\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.5105e-05 - accuracy: 1.0000 - val_loss: 2.8523 - val_accuracy: 0.6949\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.4718e-05 - accuracy: 1.0000 - val_loss: 2.8559 - val_accuracy: 0.6949\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 2.4353e-05 - accuracy: 1.0000 - val_loss: 2.8597 - val_accuracy: 0.6949\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.3987e-05 - accuracy: 1.0000 - val_loss: 2.8634 - val_accuracy: 0.6949\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.3638e-05 - accuracy: 1.0000 - val_loss: 2.8669 - val_accuracy: 0.6949\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.3289e-05 - accuracy: 1.0000 - val_loss: 2.8706 - val_accuracy: 0.6949\n",
      "Epoch 279/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 98ms/step - loss: 2.2938e-05 - accuracy: 1.0000 - val_loss: 2.8743 - val_accuracy: 0.6949\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.2601e-05 - accuracy: 1.0000 - val_loss: 2.8779 - val_accuracy: 0.6949\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 2.2279e-05 - accuracy: 1.0000 - val_loss: 2.8816 - val_accuracy: 0.6949\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.1950e-05 - accuracy: 1.0000 - val_loss: 2.8853 - val_accuracy: 0.6949\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.1629e-05 - accuracy: 1.0000 - val_loss: 2.8887 - val_accuracy: 0.6949\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.1304e-05 - accuracy: 1.0000 - val_loss: 2.8925 - val_accuracy: 0.6949\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.0995e-05 - accuracy: 1.0000 - val_loss: 2.8960 - val_accuracy: 0.6949\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.0696e-05 - accuracy: 1.0000 - val_loss: 2.8993 - val_accuracy: 0.6949\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 2.0391e-05 - accuracy: 1.0000 - val_loss: 2.9030 - val_accuracy: 0.6949\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.0093e-05 - accuracy: 1.0000 - val_loss: 2.9067 - val_accuracy: 0.6949\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.9813e-05 - accuracy: 1.0000 - val_loss: 2.9100 - val_accuracy: 0.6949\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.9516e-05 - accuracy: 1.0000 - val_loss: 2.9137 - val_accuracy: 0.6949\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.9233e-05 - accuracy: 1.0000 - val_loss: 2.9171 - val_accuracy: 0.6949\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.8963e-05 - accuracy: 1.0000 - val_loss: 2.9205 - val_accuracy: 0.6949\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.8688e-05 - accuracy: 1.0000 - val_loss: 2.9242 - val_accuracy: 0.7034\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.8420e-05 - accuracy: 1.0000 - val_loss: 2.9276 - val_accuracy: 0.6949\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.8160e-05 - accuracy: 1.0000 - val_loss: 2.9310 - val_accuracy: 0.7034\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.7909e-05 - accuracy: 1.0000 - val_loss: 2.9346 - val_accuracy: 0.7034\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.7650e-05 - accuracy: 1.0000 - val_loss: 2.9381 - val_accuracy: 0.7034\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.7400e-05 - accuracy: 1.0000 - val_loss: 2.9414 - val_accuracy: 0.7034\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 1.7159e-05 - accuracy: 1.0000 - val_loss: 2.9450 - val_accuracy: 0.7034\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.6914e-05 - accuracy: 1.0000 - val_loss: 2.9485 - val_accuracy: 0.7034\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.6677e-05 - accuracy: 1.0000 - val_loss: 2.9518 - val_accuracy: 0.7034\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.6437e-05 - accuracy: 1.0000 - val_loss: 2.9554 - val_accuracy: 0.7034\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.6207e-05 - accuracy: 1.0000 - val_loss: 2.9588 - val_accuracy: 0.7034\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.5989e-05 - accuracy: 1.0000 - val_loss: 2.9624 - val_accuracy: 0.7034\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 1.5759e-05 - accuracy: 1.0000 - val_loss: 2.9656 - val_accuracy: 0.7034\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.5538e-05 - accuracy: 1.0000 - val_loss: 2.9693 - val_accuracy: 0.7034\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.5333e-05 - accuracy: 1.0000 - val_loss: 2.9725 - val_accuracy: 0.7034\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.5101e-05 - accuracy: 1.0000 - val_loss: 2.9762 - val_accuracy: 0.7034\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.4898e-05 - accuracy: 1.0000 - val_loss: 2.9795 - val_accuracy: 0.7034\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.4693e-05 - accuracy: 1.0000 - val_loss: 2.9830 - val_accuracy: 0.7034\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.4475e-05 - accuracy: 1.0000 - val_loss: 2.9866 - val_accuracy: 0.7034\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 1.4279e-05 - accuracy: 1.0000 - val_loss: 2.9899 - val_accuracy: 0.7034\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.4076e-05 - accuracy: 1.0000 - val_loss: 2.9932 - val_accuracy: 0.7034\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.3881e-05 - accuracy: 1.0000 - val_loss: 2.9968 - val_accuracy: 0.7034\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.3690e-05 - accuracy: 1.0000 - val_loss: 3.0003 - val_accuracy: 0.7034\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.3502e-05 - accuracy: 1.0000 - val_loss: 3.0034 - val_accuracy: 0.7034\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.3305e-05 - accuracy: 1.0000 - val_loss: 3.0069 - val_accuracy: 0.7034\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.3128e-05 - accuracy: 1.0000 - val_loss: 3.0104 - val_accuracy: 0.7034\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.2935e-05 - accuracy: 1.0000 - val_loss: 3.0138 - val_accuracy: 0.7034\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.2756e-05 - accuracy: 1.0000 - val_loss: 3.0171 - val_accuracy: 0.7034\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.2581e-05 - accuracy: 1.0000 - val_loss: 3.0203 - val_accuracy: 0.7034\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.2400e-05 - accuracy: 1.0000 - val_loss: 3.0239 - val_accuracy: 0.7034\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.2235e-05 - accuracy: 1.0000 - val_loss: 3.0271 - val_accuracy: 0.7034\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 1.2059e-05 - accuracy: 1.0000 - val_loss: 3.0305 - val_accuracy: 0.7034\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.1898e-05 - accuracy: 1.0000 - val_loss: 3.0339 - val_accuracy: 0.7034\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.1728e-05 - accuracy: 1.0000 - val_loss: 3.0371 - val_accuracy: 0.7034\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.1567e-05 - accuracy: 1.0000 - val_loss: 3.0407 - val_accuracy: 0.7034\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.1411e-05 - accuracy: 1.0000 - val_loss: 3.0439 - val_accuracy: 0.7034\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.1262e-05 - accuracy: 1.0000 - val_loss: 3.0472 - val_accuracy: 0.7034\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.1093e-05 - accuracy: 1.0000 - val_loss: 3.0508 - val_accuracy: 0.7034\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 1.0956e-05 - accuracy: 1.0000 - val_loss: 3.0539 - val_accuracy: 0.7034\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.0804e-05 - accuracy: 1.0000 - val_loss: 3.0573 - val_accuracy: 0.7034\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.0659e-05 - accuracy: 1.0000 - val_loss: 3.0608 - val_accuracy: 0.7034\n",
      "Epoch 334/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 98ms/step - loss: 1.0515e-05 - accuracy: 1.0000 - val_loss: 3.0641 - val_accuracy: 0.7034\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.0364e-05 - accuracy: 1.0000 - val_loss: 3.0673 - val_accuracy: 0.7034\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.0233e-05 - accuracy: 1.0000 - val_loss: 3.0709 - val_accuracy: 0.7034\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.0098e-05 - accuracy: 1.0000 - val_loss: 3.0738 - val_accuracy: 0.7034\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 9.9649e-06 - accuracy: 1.0000 - val_loss: 3.0773 - val_accuracy: 0.7034\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 9.8307e-06 - accuracy: 1.0000 - val_loss: 3.0805 - val_accuracy: 0.7034\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 9.6954e-06 - accuracy: 1.0000 - val_loss: 3.0838 - val_accuracy: 0.7034\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 9.5699e-06 - accuracy: 1.0000 - val_loss: 3.0872 - val_accuracy: 0.7034\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 9.4518e-06 - accuracy: 1.0000 - val_loss: 3.0905 - val_accuracy: 0.7034\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 9.3156e-06 - accuracy: 1.0000 - val_loss: 3.0940 - val_accuracy: 0.7034\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 9.1974e-06 - accuracy: 1.0000 - val_loss: 3.0971 - val_accuracy: 0.7034\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 9.0681e-06 - accuracy: 1.0000 - val_loss: 3.1005 - val_accuracy: 0.7034\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 8.9580e-06 - accuracy: 1.0000 - val_loss: 3.1037 - val_accuracy: 0.7034\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 8.8345e-06 - accuracy: 1.0000 - val_loss: 3.1071 - val_accuracy: 0.7034\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 8.7158e-06 - accuracy: 1.0000 - val_loss: 3.1104 - val_accuracy: 0.7034\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 8.6032e-06 - accuracy: 1.0000 - val_loss: 3.1137 - val_accuracy: 0.7034\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 8.4804e-06 - accuracy: 1.0000 - val_loss: 3.1170 - val_accuracy: 0.7034\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 8.3757e-06 - accuracy: 1.0000 - val_loss: 3.1203 - val_accuracy: 0.7034\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 8.2633e-06 - accuracy: 1.0000 - val_loss: 3.1236 - val_accuracy: 0.7034\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 8.1548e-06 - accuracy: 1.0000 - val_loss: 3.1270 - val_accuracy: 0.7034\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 8.0543e-06 - accuracy: 1.0000 - val_loss: 3.1301 - val_accuracy: 0.7034\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 7.9453e-06 - accuracy: 1.0000 - val_loss: 3.1337 - val_accuracy: 0.7034\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 7.8500e-06 - accuracy: 1.0000 - val_loss: 3.1366 - val_accuracy: 0.7034\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 7.7409e-06 - accuracy: 1.0000 - val_loss: 3.1400 - val_accuracy: 0.7034\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 7.6395e-06 - accuracy: 1.0000 - val_loss: 3.1432 - val_accuracy: 0.7034\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 7.5440e-06 - accuracy: 1.0000 - val_loss: 3.1465 - val_accuracy: 0.7034\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 7.4442e-06 - accuracy: 1.0000 - val_loss: 3.1499 - val_accuracy: 0.7034\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 7.3472e-06 - accuracy: 1.0000 - val_loss: 3.1531 - val_accuracy: 0.7034\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 7.2457e-06 - accuracy: 1.0000 - val_loss: 3.1562 - val_accuracy: 0.7034\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 7.1582e-06 - accuracy: 1.0000 - val_loss: 3.1595 - val_accuracy: 0.7034\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 7.0687e-06 - accuracy: 1.0000 - val_loss: 3.1627 - val_accuracy: 0.7034\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.9684e-06 - accuracy: 1.0000 - val_loss: 3.1662 - val_accuracy: 0.7034\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.8878e-06 - accuracy: 1.0000 - val_loss: 3.1693 - val_accuracy: 0.7034\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 6.7976e-06 - accuracy: 1.0000 - val_loss: 3.1724 - val_accuracy: 0.7034\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 6.7163e-06 - accuracy: 1.0000 - val_loss: 3.1758 - val_accuracy: 0.7034\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.6244e-06 - accuracy: 1.0000 - val_loss: 3.1789 - val_accuracy: 0.7034\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.5414e-06 - accuracy: 1.0000 - val_loss: 3.1821 - val_accuracy: 0.7034\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 6.4519e-06 - accuracy: 1.0000 - val_loss: 3.1853 - val_accuracy: 0.7034\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 6.3792e-06 - accuracy: 1.0000 - val_loss: 3.1886 - val_accuracy: 0.7034\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 6.2967e-06 - accuracy: 1.0000 - val_loss: 3.1916 - val_accuracy: 0.7034\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.2154e-06 - accuracy: 1.0000 - val_loss: 3.1950 - val_accuracy: 0.7034\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 6.1345e-06 - accuracy: 1.0000 - val_loss: 3.1981 - val_accuracy: 0.7034\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.0549e-06 - accuracy: 1.0000 - val_loss: 3.2013 - val_accuracy: 0.7034\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 5.9756e-06 - accuracy: 1.0000 - val_loss: 3.2044 - val_accuracy: 0.7034\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 5.9007e-06 - accuracy: 1.0000 - val_loss: 3.2075 - val_accuracy: 0.7034\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 5.8243e-06 - accuracy: 1.0000 - val_loss: 3.2107 - val_accuracy: 0.7034\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 5.7447e-06 - accuracy: 1.0000 - val_loss: 3.2137 - val_accuracy: 0.7034\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 5.6712e-06 - accuracy: 1.0000 - val_loss: 3.2171 - val_accuracy: 0.7034\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 5.6052e-06 - accuracy: 1.0000 - val_loss: 3.2202 - val_accuracy: 0.7034\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 5.5319e-06 - accuracy: 1.0000 - val_loss: 3.2233 - val_accuracy: 0.7034\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 5.4655e-06 - accuracy: 1.0000 - val_loss: 3.2265 - val_accuracy: 0.7034\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 5.3940e-06 - accuracy: 1.0000 - val_loss: 3.2297 - val_accuracy: 0.7034\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 5.3221e-06 - accuracy: 1.0000 - val_loss: 3.2329 - val_accuracy: 0.7034\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 5.2515e-06 - accuracy: 1.0000 - val_loss: 3.2360 - val_accuracy: 0.7034\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 5.1895e-06 - accuracy: 1.0000 - val_loss: 3.2392 - val_accuracy: 0.7034\n",
      "Epoch 389/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 97ms/step - loss: 5.1190e-06 - accuracy: 1.0000 - val_loss: 3.2423 - val_accuracy: 0.7034\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 5.0585e-06 - accuracy: 1.0000 - val_loss: 3.2456 - val_accuracy: 0.7034\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.9952e-06 - accuracy: 1.0000 - val_loss: 3.2487 - val_accuracy: 0.7034\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.9292e-06 - accuracy: 1.0000 - val_loss: 3.2519 - val_accuracy: 0.7034\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.8658e-06 - accuracy: 1.0000 - val_loss: 3.2552 - val_accuracy: 0.7034\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.8027e-06 - accuracy: 1.0000 - val_loss: 3.2582 - val_accuracy: 0.7034\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.7479e-06 - accuracy: 1.0000 - val_loss: 3.2614 - val_accuracy: 0.7034\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.6877e-06 - accuracy: 1.0000 - val_loss: 3.2646 - val_accuracy: 0.7034\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.6262e-06 - accuracy: 1.0000 - val_loss: 3.2679 - val_accuracy: 0.7034\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.5722e-06 - accuracy: 1.0000 - val_loss: 3.2709 - val_accuracy: 0.7034\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.5065e-06 - accuracy: 1.0000 - val_loss: 3.2739 - val_accuracy: 0.7034\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.4503e-06 - accuracy: 1.0000 - val_loss: 3.2774 - val_accuracy: 0.7034\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 4.3952e-06 - accuracy: 1.0000 - val_loss: 3.2805 - val_accuracy: 0.7034\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 4.3422e-06 - accuracy: 1.0000 - val_loss: 3.2836 - val_accuracy: 0.7034\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.2870e-06 - accuracy: 1.0000 - val_loss: 3.2870 - val_accuracy: 0.7034\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.2357e-06 - accuracy: 1.0000 - val_loss: 3.2903 - val_accuracy: 0.7034\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.1802e-06 - accuracy: 1.0000 - val_loss: 3.2933 - val_accuracy: 0.7034\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.1230e-06 - accuracy: 1.0000 - val_loss: 3.2968 - val_accuracy: 0.7034\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 4.0742e-06 - accuracy: 1.0000 - val_loss: 3.2999 - val_accuracy: 0.7034\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.0246e-06 - accuracy: 1.0000 - val_loss: 3.3030 - val_accuracy: 0.7034\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.9719e-06 - accuracy: 1.0000 - val_loss: 3.3065 - val_accuracy: 0.7034\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.9211e-06 - accuracy: 1.0000 - val_loss: 3.3097 - val_accuracy: 0.7034\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 3.8717e-06 - accuracy: 1.0000 - val_loss: 3.3130 - val_accuracy: 0.7034\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.8227e-06 - accuracy: 1.0000 - val_loss: 3.3162 - val_accuracy: 0.7034\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.7727e-06 - accuracy: 1.0000 - val_loss: 3.3193 - val_accuracy: 0.7034\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.7253e-06 - accuracy: 1.0000 - val_loss: 3.3225 - val_accuracy: 0.7034\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.6742e-06 - accuracy: 1.0000 - val_loss: 3.3257 - val_accuracy: 0.7034\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.6376e-06 - accuracy: 1.0000 - val_loss: 3.3288 - val_accuracy: 0.7034\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.5879e-06 - accuracy: 1.0000 - val_loss: 3.3318 - val_accuracy: 0.7034\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.5457e-06 - accuracy: 1.0000 - val_loss: 3.3349 - val_accuracy: 0.7034\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.5036e-06 - accuracy: 1.0000 - val_loss: 3.3379 - val_accuracy: 0.7034\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 3.4559e-06 - accuracy: 1.0000 - val_loss: 3.3412 - val_accuracy: 0.7034\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.4204e-06 - accuracy: 1.0000 - val_loss: 3.3440 - val_accuracy: 0.7034\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.3764e-06 - accuracy: 1.0000 - val_loss: 3.3470 - val_accuracy: 0.7034\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.3378e-06 - accuracy: 1.0000 - val_loss: 3.3502 - val_accuracy: 0.7034\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.2986e-06 - accuracy: 1.0000 - val_loss: 3.3532 - val_accuracy: 0.7034\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.2528e-06 - accuracy: 1.0000 - val_loss: 3.3559 - val_accuracy: 0.7034\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.2136e-06 - accuracy: 1.0000 - val_loss: 3.3592 - val_accuracy: 0.7034\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.1733e-06 - accuracy: 1.0000 - val_loss: 3.3620 - val_accuracy: 0.7034\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.1388e-06 - accuracy: 1.0000 - val_loss: 3.3649 - val_accuracy: 0.7034\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.0957e-06 - accuracy: 1.0000 - val_loss: 3.3681 - val_accuracy: 0.7034\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.0644e-06 - accuracy: 1.0000 - val_loss: 3.3710 - val_accuracy: 0.7034\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.0273e-06 - accuracy: 1.0000 - val_loss: 3.3739 - val_accuracy: 0.7034\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.9909e-06 - accuracy: 1.0000 - val_loss: 3.3770 - val_accuracy: 0.7034\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.9521e-06 - accuracy: 1.0000 - val_loss: 3.3798 - val_accuracy: 0.7034\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.9162e-06 - accuracy: 1.0000 - val_loss: 3.3830 - val_accuracy: 0.7034\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.8845e-06 - accuracy: 1.0000 - val_loss: 3.3859 - val_accuracy: 0.7034\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.8505e-06 - accuracy: 1.0000 - val_loss: 3.3889 - val_accuracy: 0.7034\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.8157e-06 - accuracy: 1.0000 - val_loss: 3.3920 - val_accuracy: 0.7034\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.7864e-06 - accuracy: 1.0000 - val_loss: 3.3948 - val_accuracy: 0.7034\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.7530e-06 - accuracy: 1.0000 - val_loss: 3.3979 - val_accuracy: 0.7034\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 2.7173e-06 - accuracy: 1.0000 - val_loss: 3.4010 - val_accuracy: 0.7034\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.6851e-06 - accuracy: 1.0000 - val_loss: 3.4037 - val_accuracy: 0.7034\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.6517e-06 - accuracy: 1.0000 - val_loss: 3.4067 - val_accuracy: 0.7034\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 2.6177e-06 - accuracy: 1.0000 - val_loss: 3.4098 - val_accuracy: 0.7034\n",
      "Epoch 444/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 97ms/step - loss: 2.5913e-06 - accuracy: 1.0000 - val_loss: 3.4127 - val_accuracy: 0.7034\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 2.5604e-06 - accuracy: 1.0000 - val_loss: 3.4156 - val_accuracy: 0.7034\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.5285e-06 - accuracy: 1.0000 - val_loss: 3.4187 - val_accuracy: 0.7034\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.5007e-06 - accuracy: 1.0000 - val_loss: 3.4215 - val_accuracy: 0.7034\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 2.4677e-06 - accuracy: 1.0000 - val_loss: 3.4246 - val_accuracy: 0.7034\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.4421e-06 - accuracy: 1.0000 - val_loss: 3.4274 - val_accuracy: 0.7034\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.4116e-06 - accuracy: 1.0000 - val_loss: 3.4306 - val_accuracy: 0.7034\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.3810e-06 - accuracy: 1.0000 - val_loss: 3.4332 - val_accuracy: 0.7034\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.3538e-06 - accuracy: 1.0000 - val_loss: 3.4363 - val_accuracy: 0.7034\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 2.3253e-06 - accuracy: 1.0000 - val_loss: 3.4394 - val_accuracy: 0.7034\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 2.3010e-06 - accuracy: 1.0000 - val_loss: 3.4422 - val_accuracy: 0.7034\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.2761e-06 - accuracy: 1.0000 - val_loss: 3.4452 - val_accuracy: 0.7034\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.2507e-06 - accuracy: 1.0000 - val_loss: 3.4481 - val_accuracy: 0.7034\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 2.2247e-06 - accuracy: 1.0000 - val_loss: 3.4511 - val_accuracy: 0.7034\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.1944e-06 - accuracy: 1.0000 - val_loss: 3.4540 - val_accuracy: 0.7034\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 2.1677e-06 - accuracy: 1.0000 - val_loss: 3.4569 - val_accuracy: 0.7034\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.1462e-06 - accuracy: 1.0000 - val_loss: 3.4599 - val_accuracy: 0.7034\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.1157e-06 - accuracy: 1.0000 - val_loss: 3.4629 - val_accuracy: 0.7034\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.0926e-06 - accuracy: 1.0000 - val_loss: 3.4657 - val_accuracy: 0.7034\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.0685e-06 - accuracy: 1.0000 - val_loss: 3.4686 - val_accuracy: 0.7034\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.0447e-06 - accuracy: 1.0000 - val_loss: 3.4716 - val_accuracy: 0.7034\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.0218e-06 - accuracy: 1.0000 - val_loss: 3.4745 - val_accuracy: 0.7034\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.9972e-06 - accuracy: 1.0000 - val_loss: 3.4773 - val_accuracy: 0.7034\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 1.9753e-06 - accuracy: 1.0000 - val_loss: 3.4803 - val_accuracy: 0.7034\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.9575e-06 - accuracy: 1.0000 - val_loss: 3.4833 - val_accuracy: 0.7034\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.9338e-06 - accuracy: 1.0000 - val_loss: 3.4862 - val_accuracy: 0.7034\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.9050e-06 - accuracy: 1.0000 - val_loss: 3.4891 - val_accuracy: 0.7034\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.8872e-06 - accuracy: 1.0000 - val_loss: 3.4920 - val_accuracy: 0.7034\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.8658e-06 - accuracy: 1.0000 - val_loss: 3.4950 - val_accuracy: 0.7034\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.8422e-06 - accuracy: 1.0000 - val_loss: 3.4978 - val_accuracy: 0.7034\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.8190e-06 - accuracy: 1.0000 - val_loss: 3.5008 - val_accuracy: 0.7034\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.7994e-06 - accuracy: 1.0000 - val_loss: 3.5036 - val_accuracy: 0.7034\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.7779e-06 - accuracy: 1.0000 - val_loss: 3.5066 - val_accuracy: 0.7034\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.7568e-06 - accuracy: 1.0000 - val_loss: 3.5096 - val_accuracy: 0.7034\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.7392e-06 - accuracy: 1.0000 - val_loss: 3.5124 - val_accuracy: 0.7034\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.7175e-06 - accuracy: 1.0000 - val_loss: 3.5154 - val_accuracy: 0.7034\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.6978e-06 - accuracy: 1.0000 - val_loss: 3.5182 - val_accuracy: 0.7034\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 1.6814e-06 - accuracy: 1.0000 - val_loss: 3.5211 - val_accuracy: 0.7034\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.6639e-06 - accuracy: 1.0000 - val_loss: 3.5240 - val_accuracy: 0.7034\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.6446e-06 - accuracy: 1.0000 - val_loss: 3.5269 - val_accuracy: 0.7034\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.6227e-06 - accuracy: 1.0000 - val_loss: 3.5296 - val_accuracy: 0.7034\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.6048e-06 - accuracy: 1.0000 - val_loss: 3.5325 - val_accuracy: 0.7034\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.5855e-06 - accuracy: 1.0000 - val_loss: 3.5354 - val_accuracy: 0.7034\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.5685e-06 - accuracy: 1.0000 - val_loss: 3.5383 - val_accuracy: 0.7034\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.5482e-06 - accuracy: 1.0000 - val_loss: 3.5410 - val_accuracy: 0.7034\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.5305e-06 - accuracy: 1.0000 - val_loss: 3.5440 - val_accuracy: 0.7034\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.5157e-06 - accuracy: 1.0000 - val_loss: 3.5467 - val_accuracy: 0.7034\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.5011e-06 - accuracy: 1.0000 - val_loss: 3.5497 - val_accuracy: 0.7034\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.4816e-06 - accuracy: 1.0000 - val_loss: 3.5526 - val_accuracy: 0.7034\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.4678e-06 - accuracy: 1.0000 - val_loss: 3.5555 - val_accuracy: 0.7034\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.4505e-06 - accuracy: 1.0000 - val_loss: 3.5583 - val_accuracy: 0.7034\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.4357e-06 - accuracy: 1.0000 - val_loss: 3.5613 - val_accuracy: 0.7034\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.4148e-06 - accuracy: 1.0000 - val_loss: 3.5641 - val_accuracy: 0.7034\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.3973e-06 - accuracy: 1.0000 - val_loss: 3.5670 - val_accuracy: 0.7034\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.3830e-06 - accuracy: 1.0000 - val_loss: 3.5700 - val_accuracy: 0.7034\n",
      "Epoch 499/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 97ms/step - loss: 1.3700e-06 - accuracy: 1.0000 - val_loss: 3.5729 - val_accuracy: 0.7034\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.3535e-06 - accuracy: 1.0000 - val_loss: 3.5758 - val_accuracy: 0.7034\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.3390e-06 - accuracy: 1.0000 - val_loss: 3.5785 - val_accuracy: 0.7034\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.3229e-06 - accuracy: 1.0000 - val_loss: 3.5813 - val_accuracy: 0.7034\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.3091e-06 - accuracy: 1.0000 - val_loss: 3.5843 - val_accuracy: 0.7034\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.2958e-06 - accuracy: 1.0000 - val_loss: 3.5870 - val_accuracy: 0.7034\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.2800e-06 - accuracy: 1.0000 - val_loss: 3.5899 - val_accuracy: 0.7034\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 1.2664e-06 - accuracy: 1.0000 - val_loss: 3.5926 - val_accuracy: 0.7034\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.2500e-06 - accuracy: 1.0000 - val_loss: 3.5955 - val_accuracy: 0.7034\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.2369e-06 - accuracy: 1.0000 - val_loss: 3.5983 - val_accuracy: 0.7034\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.2239e-06 - accuracy: 1.0000 - val_loss: 3.6011 - val_accuracy: 0.7034\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.2126e-06 - accuracy: 1.0000 - val_loss: 3.6041 - val_accuracy: 0.7034\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.1970e-06 - accuracy: 1.0000 - val_loss: 3.6070 - val_accuracy: 0.7034\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.1828e-06 - accuracy: 1.0000 - val_loss: 3.6100 - val_accuracy: 0.7034\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.1711e-06 - accuracy: 1.0000 - val_loss: 3.6128 - val_accuracy: 0.7034\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.1565e-06 - accuracy: 1.0000 - val_loss: 3.6160 - val_accuracy: 0.7034\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.1422e-06 - accuracy: 1.0000 - val_loss: 3.6188 - val_accuracy: 0.7034\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.1285e-06 - accuracy: 1.0000 - val_loss: 3.6217 - val_accuracy: 0.7034\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.1134e-06 - accuracy: 1.0000 - val_loss: 3.6247 - val_accuracy: 0.7034\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.1020e-06 - accuracy: 1.0000 - val_loss: 3.6275 - val_accuracy: 0.7034\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.0897e-06 - accuracy: 1.0000 - val_loss: 3.6304 - val_accuracy: 0.7034\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.0822e-06 - accuracy: 1.0000 - val_loss: 3.6334 - val_accuracy: 0.7034\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.0693e-06 - accuracy: 1.0000 - val_loss: 3.6364 - val_accuracy: 0.7034\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.0508e-06 - accuracy: 1.0000 - val_loss: 3.6394 - val_accuracy: 0.7034\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.0447e-06 - accuracy: 1.0000 - val_loss: 3.6424 - val_accuracy: 0.7034\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.0286e-06 - accuracy: 1.0000 - val_loss: 3.6454 - val_accuracy: 0.7034\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.0185e-06 - accuracy: 1.0000 - val_loss: 3.6484 - val_accuracy: 0.7034\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 2s 101ms/step - loss: 1.0080e-06 - accuracy: 1.0000 - val_loss: 3.6517 - val_accuracy: 0.7034\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 9.9395e-07 - accuracy: 1.0000 - val_loss: 3.6547 - val_accuracy: 0.7034\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 9.8525e-07 - accuracy: 1.0000 - val_loss: 3.6579 - val_accuracy: 0.7034\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 9.7136e-07 - accuracy: 1.0000 - val_loss: 3.6614 - val_accuracy: 0.7034\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 9.5927e-07 - accuracy: 1.0000 - val_loss: 3.6648 - val_accuracy: 0.7034\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 9.5199e-07 - accuracy: 1.0000 - val_loss: 3.6683 - val_accuracy: 0.7034\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 9.4155e-07 - accuracy: 1.0000 - val_loss: 3.6724 - val_accuracy: 0.7034\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 9.2595e-07 - accuracy: 1.0000 - val_loss: 3.6765 - val_accuracy: 0.7034\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 9.1072e-07 - accuracy: 1.0000 - val_loss: 3.6809 - val_accuracy: 0.7034\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 8.9961e-07 - accuracy: 1.0000 - val_loss: 3.6859 - val_accuracy: 0.7034\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 8.8649e-07 - accuracy: 1.0000 - val_loss: 3.6909 - val_accuracy: 0.7034\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 8.7146e-07 - accuracy: 1.0000 - val_loss: 3.6953 - val_accuracy: 0.7034\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 8.5870e-07 - accuracy: 1.0000 - val_loss: 3.6990 - val_accuracy: 0.7034\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 8.4839e-07 - accuracy: 1.0000 - val_loss: 3.7028 - val_accuracy: 0.7034\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 8.3291e-07 - accuracy: 1.0000 - val_loss: 3.7058 - val_accuracy: 0.7034\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 8.2466e-07 - accuracy: 1.0000 - val_loss: 3.7086 - val_accuracy: 0.7034\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 2s 102ms/step - loss: 8.1664e-07 - accuracy: 1.0000 - val_loss: 3.7113 - val_accuracy: 0.7034\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 8.0868e-07 - accuracy: 1.0000 - val_loss: 3.7135 - val_accuracy: 0.7034\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 7.9980e-07 - accuracy: 1.0000 - val_loss: 3.7160 - val_accuracy: 0.7034\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 7.8781e-07 - accuracy: 1.0000 - val_loss: 3.7185 - val_accuracy: 0.7034\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 2s 101ms/step - loss: 7.8216e-07 - accuracy: 1.0000 - val_loss: 3.7210 - val_accuracy: 0.7034\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 2s 101ms/step - loss: 7.7213e-07 - accuracy: 1.0000 - val_loss: 3.7235 - val_accuracy: 0.7034\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 7.6122e-07 - accuracy: 1.0000 - val_loss: 3.7263 - val_accuracy: 0.7034\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 7.5641e-07 - accuracy: 1.0000 - val_loss: 3.7288 - val_accuracy: 0.7034\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 7.4915e-07 - accuracy: 1.0000 - val_loss: 3.7313 - val_accuracy: 0.7034\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 7.3981e-07 - accuracy: 1.0000 - val_loss: 3.7340 - val_accuracy: 0.7034\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 7.3558e-07 - accuracy: 1.0000 - val_loss: 3.7365 - val_accuracy: 0.7034\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 7.2376e-07 - accuracy: 1.0000 - val_loss: 3.7391 - val_accuracy: 0.7034\n",
      "Epoch 554/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 97ms/step - loss: 7.1554e-07 - accuracy: 1.0000 - val_loss: 3.7420 - val_accuracy: 0.7034\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 7.0978e-07 - accuracy: 1.0000 - val_loss: 3.7448 - val_accuracy: 0.7034\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 7.0153e-07 - accuracy: 1.0000 - val_loss: 3.7474 - val_accuracy: 0.7034\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.9489e-07 - accuracy: 1.0000 - val_loss: 3.7506 - val_accuracy: 0.7034\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.8803e-07 - accuracy: 1.0000 - val_loss: 3.7531 - val_accuracy: 0.7034\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.8235e-07 - accuracy: 1.0000 - val_loss: 3.7561 - val_accuracy: 0.7034\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.7434e-07 - accuracy: 1.0000 - val_loss: 3.7588 - val_accuracy: 0.7034\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.6584e-07 - accuracy: 1.0000 - val_loss: 3.7614 - val_accuracy: 0.7034\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.5700e-07 - accuracy: 1.0000 - val_loss: 3.7639 - val_accuracy: 0.7034\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.4996e-07 - accuracy: 1.0000 - val_loss: 3.7668 - val_accuracy: 0.7034\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.3979e-07 - accuracy: 1.0000 - val_loss: 3.7694 - val_accuracy: 0.7034\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 6.3228e-07 - accuracy: 1.0000 - val_loss: 3.7721 - val_accuracy: 0.7034\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.2701e-07 - accuracy: 1.0000 - val_loss: 3.7748 - val_accuracy: 0.7034\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.2352e-07 - accuracy: 1.0000 - val_loss: 3.7776 - val_accuracy: 0.7034\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.1865e-07 - accuracy: 1.0000 - val_loss: 3.7802 - val_accuracy: 0.7034\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.1085e-07 - accuracy: 1.0000 - val_loss: 3.7828 - val_accuracy: 0.7034\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 6.0521e-07 - accuracy: 1.0000 - val_loss: 3.7851 - val_accuracy: 0.7034\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 5.9620e-07 - accuracy: 1.0000 - val_loss: 3.7878 - val_accuracy: 0.7034\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 5.8974e-07 - accuracy: 1.0000 - val_loss: 3.7902 - val_accuracy: 0.7034\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 5.8136e-07 - accuracy: 1.0000 - val_loss: 3.7929 - val_accuracy: 0.7034\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 5.7773e-07 - accuracy: 1.0000 - val_loss: 3.7956 - val_accuracy: 0.7034\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 5.7002e-07 - accuracy: 1.0000 - val_loss: 3.7984 - val_accuracy: 0.7034\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 5.6295e-07 - accuracy: 1.0000 - val_loss: 3.8010 - val_accuracy: 0.7034\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 5.5701e-07 - accuracy: 1.0000 - val_loss: 3.8036 - val_accuracy: 0.7034\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 5.5471e-07 - accuracy: 1.0000 - val_loss: 3.8062 - val_accuracy: 0.7034\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 5.5034e-07 - accuracy: 1.0000 - val_loss: 3.8088 - val_accuracy: 0.7034\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 5.4365e-07 - accuracy: 1.0000 - val_loss: 3.8115 - val_accuracy: 0.7034\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 5.4002e-07 - accuracy: 1.0000 - val_loss: 3.8140 - val_accuracy: 0.7034\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 5.3196e-07 - accuracy: 1.0000 - val_loss: 3.8167 - val_accuracy: 0.7034\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 5.2494e-07 - accuracy: 1.0000 - val_loss: 3.8193 - val_accuracy: 0.7034\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 5.1973e-07 - accuracy: 1.0000 - val_loss: 3.8217 - val_accuracy: 0.7034\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 5.1479e-07 - accuracy: 1.0000 - val_loss: 3.8242 - val_accuracy: 0.7034\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 5.0893e-07 - accuracy: 1.0000 - val_loss: 3.8267 - val_accuracy: 0.7034\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 5.0385e-07 - accuracy: 1.0000 - val_loss: 3.8293 - val_accuracy: 0.7034\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 5.0070e-07 - accuracy: 1.0000 - val_loss: 3.8316 - val_accuracy: 0.7034\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.9162e-07 - accuracy: 1.0000 - val_loss: 3.8343 - val_accuracy: 0.7034\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 4.8875e-07 - accuracy: 1.0000 - val_loss: 3.8371 - val_accuracy: 0.7034\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.8255e-07 - accuracy: 1.0000 - val_loss: 3.8397 - val_accuracy: 0.7034\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.7650e-07 - accuracy: 1.0000 - val_loss: 3.8425 - val_accuracy: 0.7034\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 4.7185e-07 - accuracy: 1.0000 - val_loss: 3.8452 - val_accuracy: 0.7034\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 4.6889e-07 - accuracy: 1.0000 - val_loss: 3.8478 - val_accuracy: 0.7034\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.6389e-07 - accuracy: 1.0000 - val_loss: 3.8503 - val_accuracy: 0.7034\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.5948e-07 - accuracy: 1.0000 - val_loss: 3.8530 - val_accuracy: 0.7034\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 4.5609e-07 - accuracy: 1.0000 - val_loss: 3.8555 - val_accuracy: 0.7034\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 4.5094e-07 - accuracy: 1.0000 - val_loss: 3.8584 - val_accuracy: 0.7034\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.4337e-07 - accuracy: 1.0000 - val_loss: 3.8611 - val_accuracy: 0.7034\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 4.3766e-07 - accuracy: 1.0000 - val_loss: 3.8636 - val_accuracy: 0.7034\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.3585e-07 - accuracy: 1.0000 - val_loss: 3.8661 - val_accuracy: 0.7034\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 4.2875e-07 - accuracy: 1.0000 - val_loss: 3.8687 - val_accuracy: 0.7034\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 4.2563e-07 - accuracy: 1.0000 - val_loss: 3.8711 - val_accuracy: 0.7034\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 4.2214e-07 - accuracy: 1.0000 - val_loss: 3.8734 - val_accuracy: 0.7034\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.1822e-07 - accuracy: 1.0000 - val_loss: 3.8759 - val_accuracy: 0.7034\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 4.1313e-07 - accuracy: 1.0000 - val_loss: 3.8786 - val_accuracy: 0.7034\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 4.0982e-07 - accuracy: 1.0000 - val_loss: 3.8809 - val_accuracy: 0.7034\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.0506e-07 - accuracy: 1.0000 - val_loss: 3.8836 - val_accuracy: 0.7034\n",
      "Epoch 609/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 97ms/step - loss: 4.0181e-07 - accuracy: 1.0000 - val_loss: 3.8862 - val_accuracy: 0.7034\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.9908e-07 - accuracy: 1.0000 - val_loss: 3.8886 - val_accuracy: 0.7034\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.9827e-07 - accuracy: 1.0000 - val_loss: 3.8913 - val_accuracy: 0.7034\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.9327e-07 - accuracy: 1.0000 - val_loss: 3.8939 - val_accuracy: 0.7034\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.8647e-07 - accuracy: 1.0000 - val_loss: 3.8962 - val_accuracy: 0.7034\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 3.8143e-07 - accuracy: 1.0000 - val_loss: 3.8987 - val_accuracy: 0.7034\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.7687e-07 - accuracy: 1.0000 - val_loss: 3.9012 - val_accuracy: 0.7034\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.7297e-07 - accuracy: 1.0000 - val_loss: 3.9036 - val_accuracy: 0.7034\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.7084e-07 - accuracy: 1.0000 - val_loss: 3.9062 - val_accuracy: 0.7034\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 3.6688e-07 - accuracy: 1.0000 - val_loss: 3.9083 - val_accuracy: 0.7034\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.6350e-07 - accuracy: 1.0000 - val_loss: 3.9104 - val_accuracy: 0.7034\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.5946e-07 - accuracy: 1.0000 - val_loss: 3.9131 - val_accuracy: 0.7034\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.5777e-07 - accuracy: 1.0000 - val_loss: 3.9154 - val_accuracy: 0.7034\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.5415e-07 - accuracy: 1.0000 - val_loss: 3.9179 - val_accuracy: 0.7034\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.5133e-07 - accuracy: 1.0000 - val_loss: 3.9204 - val_accuracy: 0.7034\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.4870e-07 - accuracy: 1.0000 - val_loss: 3.9226 - val_accuracy: 0.7034\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.4514e-07 - accuracy: 1.0000 - val_loss: 3.9249 - val_accuracy: 0.7034\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 3.4033e-07 - accuracy: 1.0000 - val_loss: 3.9273 - val_accuracy: 0.7034\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.3827e-07 - accuracy: 1.0000 - val_loss: 3.9296 - val_accuracy: 0.7034\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 3.3553e-07 - accuracy: 1.0000 - val_loss: 3.9320 - val_accuracy: 0.7034\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.3046e-07 - accuracy: 1.0000 - val_loss: 3.9345 - val_accuracy: 0.7034\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.2688e-07 - accuracy: 1.0000 - val_loss: 3.9369 - val_accuracy: 0.7034\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.2300e-07 - accuracy: 1.0000 - val_loss: 3.9392 - val_accuracy: 0.7034\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.1913e-07 - accuracy: 1.0000 - val_loss: 3.9416 - val_accuracy: 0.7034\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.1603e-07 - accuracy: 1.0000 - val_loss: 3.9438 - val_accuracy: 0.7034\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.1100e-07 - accuracy: 1.0000 - val_loss: 3.9463 - val_accuracy: 0.7034\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.0703e-07 - accuracy: 1.0000 - val_loss: 3.9489 - val_accuracy: 0.7034\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.0325e-07 - accuracy: 1.0000 - val_loss: 3.9513 - val_accuracy: 0.7034\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 3.0128e-07 - accuracy: 1.0000 - val_loss: 3.9540 - val_accuracy: 0.7034\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.9818e-07 - accuracy: 1.0000 - val_loss: 3.9564 - val_accuracy: 0.7034\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.9745e-07 - accuracy: 1.0000 - val_loss: 3.9588 - val_accuracy: 0.7034\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.9509e-07 - accuracy: 1.0000 - val_loss: 3.9612 - val_accuracy: 0.7034\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.9261e-07 - accuracy: 1.0000 - val_loss: 3.9635 - val_accuracy: 0.7034\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.8888e-07 - accuracy: 1.0000 - val_loss: 3.9659 - val_accuracy: 0.7034\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.8424e-07 - accuracy: 1.0000 - val_loss: 3.9684 - val_accuracy: 0.7034\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.8229e-07 - accuracy: 1.0000 - val_loss: 3.9712 - val_accuracy: 0.7034\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.8108e-07 - accuracy: 1.0000 - val_loss: 3.9739 - val_accuracy: 0.7034\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 2.7804e-07 - accuracy: 1.0000 - val_loss: 3.9766 - val_accuracy: 0.7034\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.7688e-07 - accuracy: 1.0000 - val_loss: 3.9790 - val_accuracy: 0.7034\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.7511e-07 - accuracy: 1.0000 - val_loss: 3.9817 - val_accuracy: 0.7034\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.7254e-07 - accuracy: 1.0000 - val_loss: 3.9843 - val_accuracy: 0.7034\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 2.6835e-07 - accuracy: 1.0000 - val_loss: 3.9869 - val_accuracy: 0.7034\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.6273e-07 - accuracy: 1.0000 - val_loss: 3.9896 - val_accuracy: 0.7034\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.6035e-07 - accuracy: 1.0000 - val_loss: 3.9919 - val_accuracy: 0.7034\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.5739e-07 - accuracy: 1.0000 - val_loss: 3.9944 - val_accuracy: 0.7034\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.5537e-07 - accuracy: 1.0000 - val_loss: 3.9971 - val_accuracy: 0.7034\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.5509e-07 - accuracy: 1.0000 - val_loss: 3.9997 - val_accuracy: 0.7034\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.5371e-07 - accuracy: 1.0000 - val_loss: 4.0022 - val_accuracy: 0.7034\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 2.5198e-07 - accuracy: 1.0000 - val_loss: 4.0046 - val_accuracy: 0.7034\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.5068e-07 - accuracy: 1.0000 - val_loss: 4.0069 - val_accuracy: 0.7034\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 2.4786e-07 - accuracy: 1.0000 - val_loss: 4.0098 - val_accuracy: 0.7034\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 2.4346e-07 - accuracy: 1.0000 - val_loss: 4.0125 - val_accuracy: 0.7034\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.4259e-07 - accuracy: 1.0000 - val_loss: 4.0153 - val_accuracy: 0.7034\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.4125e-07 - accuracy: 1.0000 - val_loss: 4.0177 - val_accuracy: 0.7034\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.3905e-07 - accuracy: 1.0000 - val_loss: 4.0203 - val_accuracy: 0.7034\n",
      "Epoch 664/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 98ms/step - loss: 2.3617e-07 - accuracy: 1.0000 - val_loss: 4.0227 - val_accuracy: 0.7034\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.3336e-07 - accuracy: 1.0000 - val_loss: 4.0255 - val_accuracy: 0.7034\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.2848e-07 - accuracy: 1.0000 - val_loss: 4.0282 - val_accuracy: 0.7034\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.2767e-07 - accuracy: 1.0000 - val_loss: 4.0309 - val_accuracy: 0.7034\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.2445e-07 - accuracy: 1.0000 - val_loss: 4.0335 - val_accuracy: 0.7034\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.2037e-07 - accuracy: 1.0000 - val_loss: 4.0358 - val_accuracy: 0.7034\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.1468e-07 - accuracy: 1.0000 - val_loss: 4.0381 - val_accuracy: 0.6949\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.1135e-07 - accuracy: 1.0000 - val_loss: 4.0400 - val_accuracy: 0.6949\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 2.1060e-07 - accuracy: 1.0000 - val_loss: 4.0419 - val_accuracy: 0.6949\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 2.0968e-07 - accuracy: 1.0000 - val_loss: 4.0439 - val_accuracy: 0.6949\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.0959e-07 - accuracy: 1.0000 - val_loss: 4.0459 - val_accuracy: 0.6949\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.0821e-07 - accuracy: 1.0000 - val_loss: 4.0480 - val_accuracy: 0.6949\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 2.0683e-07 - accuracy: 1.0000 - val_loss: 4.0501 - val_accuracy: 0.6949\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.0477e-07 - accuracy: 1.0000 - val_loss: 4.0523 - val_accuracy: 0.6949\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.0063e-07 - accuracy: 1.0000 - val_loss: 4.0543 - val_accuracy: 0.6949\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.9850e-07 - accuracy: 1.0000 - val_loss: 4.0565 - val_accuracy: 0.6949\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.9526e-07 - accuracy: 1.0000 - val_loss: 4.0584 - val_accuracy: 0.6949\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.9273e-07 - accuracy: 1.0000 - val_loss: 4.0605 - val_accuracy: 0.6949\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.8889e-07 - accuracy: 1.0000 - val_loss: 4.0628 - val_accuracy: 0.6949\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.8486e-07 - accuracy: 1.0000 - val_loss: 4.0654 - val_accuracy: 0.6949\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.8455e-07 - accuracy: 1.0000 - val_loss: 4.0678 - val_accuracy: 0.6949\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.8284e-07 - accuracy: 1.0000 - val_loss: 4.0702 - val_accuracy: 0.6949\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.8074e-07 - accuracy: 1.0000 - val_loss: 4.0723 - val_accuracy: 0.6949\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 1.8062e-07 - accuracy: 1.0000 - val_loss: 4.0746 - val_accuracy: 0.6949\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.7900e-07 - accuracy: 1.0000 - val_loss: 4.0765 - val_accuracy: 0.6949\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 2s 101ms/step - loss: 1.7829e-07 - accuracy: 1.0000 - val_loss: 4.0785 - val_accuracy: 0.6949\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 1.7710e-07 - accuracy: 1.0000 - val_loss: 4.0807 - val_accuracy: 0.6949\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 1.7288e-07 - accuracy: 1.0000 - val_loss: 4.0830 - val_accuracy: 0.6949\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 1.7270e-07 - accuracy: 1.0000 - val_loss: 4.0852 - val_accuracy: 0.6949\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.7212e-07 - accuracy: 1.0000 - val_loss: 4.0874 - val_accuracy: 0.6949\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.7032e-07 - accuracy: 1.0000 - val_loss: 4.0897 - val_accuracy: 0.6949\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.6704e-07 - accuracy: 1.0000 - val_loss: 4.0922 - val_accuracy: 0.6949\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.6436e-07 - accuracy: 1.0000 - val_loss: 4.0948 - val_accuracy: 0.6949\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.6424e-07 - accuracy: 1.0000 - val_loss: 4.0973 - val_accuracy: 0.6949\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 1.6323e-07 - accuracy: 1.0000 - val_loss: 4.0997 - val_accuracy: 0.6949\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.6302e-07 - accuracy: 1.0000 - val_loss: 4.1018 - val_accuracy: 0.6949\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.6202e-07 - accuracy: 1.0000 - val_loss: 4.1040 - val_accuracy: 0.6949\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.6103e-07 - accuracy: 1.0000 - val_loss: 4.1060 - val_accuracy: 0.6949\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.5960e-07 - accuracy: 1.0000 - val_loss: 4.1084 - val_accuracy: 0.6949\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.5927e-07 - accuracy: 1.0000 - val_loss: 4.1106 - val_accuracy: 0.6949\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.5772e-07 - accuracy: 1.0000 - val_loss: 4.1128 - val_accuracy: 0.6949\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.5667e-07 - accuracy: 1.0000 - val_loss: 4.1149 - val_accuracy: 0.6949\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.5608e-07 - accuracy: 1.0000 - val_loss: 4.1171 - val_accuracy: 0.6949\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.5482e-07 - accuracy: 1.0000 - val_loss: 4.1192 - val_accuracy: 0.6949\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.5326e-07 - accuracy: 1.0000 - val_loss: 4.1215 - val_accuracy: 0.6949\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.5279e-07 - accuracy: 1.0000 - val_loss: 4.1236 - val_accuracy: 0.6949\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.5221e-07 - accuracy: 1.0000 - val_loss: 4.1261 - val_accuracy: 0.6949\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.5008e-07 - accuracy: 1.0000 - val_loss: 4.1284 - val_accuracy: 0.6949\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.4721e-07 - accuracy: 1.0000 - val_loss: 4.1310 - val_accuracy: 0.6949\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.4454e-07 - accuracy: 1.0000 - val_loss: 4.1333 - val_accuracy: 0.6949\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.4229e-07 - accuracy: 1.0000 - val_loss: 4.1356 - val_accuracy: 0.6949\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.4086e-07 - accuracy: 1.0000 - val_loss: 4.1381 - val_accuracy: 0.6949\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.3982e-07 - accuracy: 1.0000 - val_loss: 4.1403 - val_accuracy: 0.6949\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.3982e-07 - accuracy: 1.0000 - val_loss: 4.1423 - val_accuracy: 0.6949\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.3806e-07 - accuracy: 1.0000 - val_loss: 4.1445 - val_accuracy: 0.6949\n",
      "Epoch 719/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 98ms/step - loss: 1.3678e-07 - accuracy: 1.0000 - val_loss: 4.1465 - val_accuracy: 0.6949\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 1.3576e-07 - accuracy: 1.0000 - val_loss: 4.1486 - val_accuracy: 0.6949\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.3538e-07 - accuracy: 1.0000 - val_loss: 4.1506 - val_accuracy: 0.6949\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.3396e-07 - accuracy: 1.0000 - val_loss: 4.1527 - val_accuracy: 0.6949\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 1.3315e-07 - accuracy: 1.0000 - val_loss: 4.1545 - val_accuracy: 0.6949\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 1.3229e-07 - accuracy: 1.0000 - val_loss: 4.1564 - val_accuracy: 0.6949\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.3129e-07 - accuracy: 1.0000 - val_loss: 4.1582 - val_accuracy: 0.6949\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 1.3052e-07 - accuracy: 1.0000 - val_loss: 4.1596 - val_accuracy: 0.6949\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 1.2951e-07 - accuracy: 1.0000 - val_loss: 4.1617 - val_accuracy: 0.6949\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 1.2748e-07 - accuracy: 1.0000 - val_loss: 4.1643 - val_accuracy: 0.6949\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.2649e-07 - accuracy: 1.0000 - val_loss: 4.1665 - val_accuracy: 0.6949\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.2343e-07 - accuracy: 1.0000 - val_loss: 4.1687 - val_accuracy: 0.6949\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.2305e-07 - accuracy: 1.0000 - val_loss: 4.1712 - val_accuracy: 0.6949\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.2195e-07 - accuracy: 1.0000 - val_loss: 4.1733 - val_accuracy: 0.6949\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.2025e-07 - accuracy: 1.0000 - val_loss: 4.1757 - val_accuracy: 0.6949\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.1844e-07 - accuracy: 1.0000 - val_loss: 4.1783 - val_accuracy: 0.6949\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.1823e-07 - accuracy: 1.0000 - val_loss: 4.1809 - val_accuracy: 0.6949\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.1823e-07 - accuracy: 1.0000 - val_loss: 4.1833 - val_accuracy: 0.6949\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.1567e-07 - accuracy: 1.0000 - val_loss: 4.1855 - val_accuracy: 0.6949\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.1487e-07 - accuracy: 1.0000 - val_loss: 4.1877 - val_accuracy: 0.6949\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.1419e-07 - accuracy: 1.0000 - val_loss: 4.1901 - val_accuracy: 0.6949\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.1361e-07 - accuracy: 1.0000 - val_loss: 4.1921 - val_accuracy: 0.6949\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.1319e-07 - accuracy: 1.0000 - val_loss: 4.1941 - val_accuracy: 0.6949\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.1294e-07 - accuracy: 1.0000 - val_loss: 4.1961 - val_accuracy: 0.6949\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.1170e-07 - accuracy: 1.0000 - val_loss: 4.1984 - val_accuracy: 0.6949\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.0974e-07 - accuracy: 1.0000 - val_loss: 4.2003 - val_accuracy: 0.6949\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.0974e-07 - accuracy: 1.0000 - val_loss: 4.2022 - val_accuracy: 0.6949\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.0962e-07 - accuracy: 1.0000 - val_loss: 4.2040 - val_accuracy: 0.6949\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.0686e-07 - accuracy: 1.0000 - val_loss: 4.2058 - val_accuracy: 0.6949\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.0497e-07 - accuracy: 1.0000 - val_loss: 4.2077 - val_accuracy: 0.6949\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.0416e-07 - accuracy: 1.0000 - val_loss: 4.2095 - val_accuracy: 0.6949\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.0336e-07 - accuracy: 1.0000 - val_loss: 4.2112 - val_accuracy: 0.6949\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 1.0196e-07 - accuracy: 1.0000 - val_loss: 4.2131 - val_accuracy: 0.6949\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.0167e-07 - accuracy: 1.0000 - val_loss: 4.2153 - val_accuracy: 0.6949\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.0134e-07 - accuracy: 1.0000 - val_loss: 4.2174 - val_accuracy: 0.6949\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.0042e-07 - accuracy: 1.0000 - val_loss: 4.2198 - val_accuracy: 0.6949\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.0015e-07 - accuracy: 1.0000 - val_loss: 4.2222 - val_accuracy: 0.6949\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 9.9005e-08 - accuracy: 1.0000 - val_loss: 4.2242 - val_accuracy: 0.6949\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 9.7611e-08 - accuracy: 1.0000 - val_loss: 4.2264 - val_accuracy: 0.6949\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 9.6940e-08 - accuracy: 1.0000 - val_loss: 4.2284 - val_accuracy: 0.6949\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 9.5939e-08 - accuracy: 1.0000 - val_loss: 4.2305 - val_accuracy: 0.6949\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 9.5939e-08 - accuracy: 1.0000 - val_loss: 4.2324 - val_accuracy: 0.6949\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 9.5761e-08 - accuracy: 1.0000 - val_loss: 4.2345 - val_accuracy: 0.6949\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 9.4368e-08 - accuracy: 1.0000 - val_loss: 4.2368 - val_accuracy: 0.6949\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 9.1769e-08 - accuracy: 1.0000 - val_loss: 4.2394 - val_accuracy: 0.6949\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 9.1440e-08 - accuracy: 1.0000 - val_loss: 4.2419 - val_accuracy: 0.6949\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 8.9928e-08 - accuracy: 1.0000 - val_loss: 4.2443 - val_accuracy: 0.6949\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 8.8912e-08 - accuracy: 1.0000 - val_loss: 4.2462 - val_accuracy: 0.6949\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 8.8560e-08 - accuracy: 1.0000 - val_loss: 4.2483 - val_accuracy: 0.6949\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 8.8542e-08 - accuracy: 1.0000 - val_loss: 4.2504 - val_accuracy: 0.6949\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 8.8080e-08 - accuracy: 1.0000 - val_loss: 4.2524 - val_accuracy: 0.6949\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 8.7253e-08 - accuracy: 1.0000 - val_loss: 4.2544 - val_accuracy: 0.6949\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 8.6667e-08 - accuracy: 1.0000 - val_loss: 4.2563 - val_accuracy: 0.6949\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 8.4860e-08 - accuracy: 1.0000 - val_loss: 4.2586 - val_accuracy: 0.6949\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 8.4429e-08 - accuracy: 1.0000 - val_loss: 4.2605 - val_accuracy: 0.6949\n",
      "Epoch 774/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 98ms/step - loss: 8.4214e-08 - accuracy: 1.0000 - val_loss: 4.2627 - val_accuracy: 0.6949\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 8.2647e-08 - accuracy: 1.0000 - val_loss: 4.2648 - val_accuracy: 0.6949\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 8.1860e-08 - accuracy: 1.0000 - val_loss: 4.2668 - val_accuracy: 0.6949\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 8.2188e-08 - accuracy: 1.0000 - val_loss: 4.2687 - val_accuracy: 0.6949\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 8.0466e-08 - accuracy: 1.0000 - val_loss: 4.2706 - val_accuracy: 0.6949\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 8.0524e-08 - accuracy: 1.0000 - val_loss: 4.2722 - val_accuracy: 0.6949\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 7.9660e-08 - accuracy: 1.0000 - val_loss: 4.2744 - val_accuracy: 0.6949\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 7.5912e-08 - accuracy: 1.0000 - val_loss: 4.2758 - val_accuracy: 0.6949\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 7.5170e-08 - accuracy: 1.0000 - val_loss: 4.2782 - val_accuracy: 0.6949\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 7.5051e-08 - accuracy: 1.0000 - val_loss: 4.2803 - val_accuracy: 0.6949\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 7.4284e-08 - accuracy: 1.0000 - val_loss: 4.2818 - val_accuracy: 0.6949\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 7.4191e-08 - accuracy: 1.0000 - val_loss: 4.2833 - val_accuracy: 0.6949\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 7.0908e-08 - accuracy: 1.0000 - val_loss: 4.2848 - val_accuracy: 0.6949\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 7.0623e-08 - accuracy: 1.0000 - val_loss: 4.2863 - val_accuracy: 0.6949\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 7.1298e-08 - accuracy: 1.0000 - val_loss: 4.2881 - val_accuracy: 0.6949\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 7.0136e-08 - accuracy: 1.0000 - val_loss: 4.2898 - val_accuracy: 0.6949\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.9637e-08 - accuracy: 1.0000 - val_loss: 4.2918 - val_accuracy: 0.6949\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 6.9284e-08 - accuracy: 1.0000 - val_loss: 4.2937 - val_accuracy: 0.6949\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 6.8892e-08 - accuracy: 1.0000 - val_loss: 4.2956 - val_accuracy: 0.6949\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.8892e-08 - accuracy: 1.0000 - val_loss: 4.2976 - val_accuracy: 0.6949\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.8083e-08 - accuracy: 1.0000 - val_loss: 4.2993 - val_accuracy: 0.6949\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.6030e-08 - accuracy: 1.0000 - val_loss: 4.3010 - val_accuracy: 0.6949\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 6.6030e-08 - accuracy: 1.0000 - val_loss: 4.3026 - val_accuracy: 0.6949\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 6.6030e-08 - accuracy: 1.0000 - val_loss: 4.3041 - val_accuracy: 0.6949\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 6.5852e-08 - accuracy: 1.0000 - val_loss: 4.3056 - val_accuracy: 0.6949\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.3715e-08 - accuracy: 1.0000 - val_loss: 4.3076 - val_accuracy: 0.6949\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 6.3216e-08 - accuracy: 1.0000 - val_loss: 4.3092 - val_accuracy: 0.6949\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 2s 103ms/step - loss: 6.2971e-08 - accuracy: 1.0000 - val_loss: 4.3107 - val_accuracy: 0.6949\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 6.3039e-08 - accuracy: 1.0000 - val_loss: 4.3123 - val_accuracy: 0.6949\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 2s 101ms/step - loss: 6.2824e-08 - accuracy: 1.0000 - val_loss: 4.3141 - val_accuracy: 0.6949\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 6.2705e-08 - accuracy: 1.0000 - val_loss: 4.3159 - val_accuracy: 0.6949\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.1707e-08 - accuracy: 1.0000 - val_loss: 4.3180 - val_accuracy: 0.6949\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 6.2405e-08 - accuracy: 1.0000 - val_loss: 4.3200 - val_accuracy: 0.6949\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 6.0164e-08 - accuracy: 1.0000 - val_loss: 4.3213 - val_accuracy: 0.6949\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 5.8245e-08 - accuracy: 1.0000 - val_loss: 4.3235 - val_accuracy: 0.6949\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 5.7057e-08 - accuracy: 1.0000 - val_loss: 4.3256 - val_accuracy: 0.6949\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 5.6300e-08 - accuracy: 1.0000 - val_loss: 4.3273 - val_accuracy: 0.6949\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 5.6369e-08 - accuracy: 1.0000 - val_loss: 4.3289 - val_accuracy: 0.6949\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 5.6554e-08 - accuracy: 1.0000 - val_loss: 4.3310 - val_accuracy: 0.6949\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 5.5552e-08 - accuracy: 1.0000 - val_loss: 4.3325 - val_accuracy: 0.6949\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 5.5430e-08 - accuracy: 1.0000 - val_loss: 4.3342 - val_accuracy: 0.6949\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 5.4927e-08 - accuracy: 1.0000 - val_loss: 4.3356 - val_accuracy: 0.6949\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 5.4287e-08 - accuracy: 1.0000 - val_loss: 4.3374 - val_accuracy: 0.6949\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 5.4151e-08 - accuracy: 1.0000 - val_loss: 4.3391 - val_accuracy: 0.6949\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 5.4677e-08 - accuracy: 1.0000 - val_loss: 4.3408 - val_accuracy: 0.6949\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 5.4261e-08 - accuracy: 1.0000 - val_loss: 4.3427 - val_accuracy: 0.6949\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 5.3754e-08 - accuracy: 1.0000 - val_loss: 4.3443 - val_accuracy: 0.6949\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 5.3264e-08 - accuracy: 1.0000 - val_loss: 4.3463 - val_accuracy: 0.6949\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 5.3253e-08 - accuracy: 1.0000 - val_loss: 4.3476 - val_accuracy: 0.6949\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 5.2446e-08 - accuracy: 1.0000 - val_loss: 4.3487 - val_accuracy: 0.6949\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 5.2217e-08 - accuracy: 1.0000 - val_loss: 4.3496 - val_accuracy: 0.6949\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 5.2100e-08 - accuracy: 1.0000 - val_loss: 4.3503 - val_accuracy: 0.6949\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 5.1488e-08 - accuracy: 1.0000 - val_loss: 4.3520 - val_accuracy: 0.6949\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 5.1179e-08 - accuracy: 1.0000 - val_loss: 4.3533 - val_accuracy: 0.6949\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 5.1203e-08 - accuracy: 1.0000 - val_loss: 4.3544 - val_accuracy: 0.6949\n",
      "Epoch 829/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 96ms/step - loss: 5.0826e-08 - accuracy: 1.0000 - val_loss: 4.3567 - val_accuracy: 0.6949\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 5.0160e-08 - accuracy: 1.0000 - val_loss: 4.3588 - val_accuracy: 0.6949\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 4.8864e-08 - accuracy: 1.0000 - val_loss: 4.3602 - val_accuracy: 0.6949\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.8579e-08 - accuracy: 1.0000 - val_loss: 4.3620 - val_accuracy: 0.6949\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 4.7485e-08 - accuracy: 1.0000 - val_loss: 4.3637 - val_accuracy: 0.6949\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 4.7343e-08 - accuracy: 1.0000 - val_loss: 4.3655 - val_accuracy: 0.6949\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.5794e-08 - accuracy: 1.0000 - val_loss: 4.3675 - val_accuracy: 0.6949\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 4.6072e-08 - accuracy: 1.0000 - val_loss: 4.3694 - val_accuracy: 0.6949\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 4.5862e-08 - accuracy: 1.0000 - val_loss: 4.3714 - val_accuracy: 0.6949\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 4.5501e-08 - accuracy: 1.0000 - val_loss: 4.3722 - val_accuracy: 0.6864\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 4.6791e-08 - accuracy: 1.0000 - val_loss: 4.3739 - val_accuracy: 0.6949\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 4.6253e-08 - accuracy: 1.0000 - val_loss: 4.3755 - val_accuracy: 0.6949\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 4.5256e-08 - accuracy: 1.0000 - val_loss: 4.3765 - val_accuracy: 0.6949\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 4.5256e-08 - accuracy: 1.0000 - val_loss: 4.3776 - val_accuracy: 0.6864\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 4.6253e-08 - accuracy: 1.0000 - val_loss: 4.3791 - val_accuracy: 0.6949\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 4.5137e-08 - accuracy: 1.0000 - val_loss: 4.3802 - val_accuracy: 0.6949\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 4.5137e-08 - accuracy: 1.0000 - val_loss: 4.3811 - val_accuracy: 0.6949\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 4.5459e-08 - accuracy: 1.0000 - val_loss: 4.3823 - val_accuracy: 0.6949\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 4.4960e-08 - accuracy: 1.0000 - val_loss: 4.3836 - val_accuracy: 0.6949\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.4960e-08 - accuracy: 1.0000 - val_loss: 4.3849 - val_accuracy: 0.6949\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 4.4960e-08 - accuracy: 1.0000 - val_loss: 4.3863 - val_accuracy: 0.6949\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 4.2772e-08 - accuracy: 1.0000 - val_loss: 4.3876 - val_accuracy: 0.6949\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 4.3349e-08 - accuracy: 1.0000 - val_loss: 4.3883 - val_accuracy: 0.6949\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 4.3577e-08 - accuracy: 1.0000 - val_loss: 4.3901 - val_accuracy: 0.6949\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.1770e-08 - accuracy: 1.0000 - val_loss: 4.3909 - val_accuracy: 0.6864\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 4.2543e-08 - accuracy: 1.0000 - val_loss: 4.3913 - val_accuracy: 0.6864\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.9570e-08 - accuracy: 1.0000 - val_loss: 4.3923 - val_accuracy: 0.6864\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 4.0953e-08 - accuracy: 1.0000 - val_loss: 4.3930 - val_accuracy: 0.6864\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.9393e-08 - accuracy: 1.0000 - val_loss: 4.3940 - val_accuracy: 0.6864\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 4.0972e-08 - accuracy: 1.0000 - val_loss: 4.3951 - val_accuracy: 0.6864\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.9393e-08 - accuracy: 1.0000 - val_loss: 4.3963 - val_accuracy: 0.6864\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.8154e-08 - accuracy: 1.0000 - val_loss: 4.3975 - val_accuracy: 0.6864\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.8960e-08 - accuracy: 1.0000 - val_loss: 4.3988 - val_accuracy: 0.6864\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.8154e-08 - accuracy: 1.0000 - val_loss: 4.3998 - val_accuracy: 0.6864\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.6943e-08 - accuracy: 1.0000 - val_loss: 4.4013 - val_accuracy: 0.6949\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.7280e-08 - accuracy: 1.0000 - val_loss: 4.4020 - val_accuracy: 0.6864\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 3.5876e-08 - accuracy: 1.0000 - val_loss: 4.4036 - val_accuracy: 0.6949\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 3.8429e-08 - accuracy: 1.0000 - val_loss: 4.4035 - val_accuracy: 0.6864\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 3.6268e-08 - accuracy: 1.0000 - val_loss: 4.4054 - val_accuracy: 0.6949\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 3.6458e-08 - accuracy: 1.0000 - val_loss: 4.4067 - val_accuracy: 0.6864\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 2s 101ms/step - loss: 3.6453e-08 - accuracy: 1.0000 - val_loss: 4.4076 - val_accuracy: 0.6949\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 3.6121e-08 - accuracy: 1.0000 - val_loss: 4.4090 - val_accuracy: 0.6949\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 3.5876e-08 - accuracy: 1.0000 - val_loss: 4.4105 - val_accuracy: 0.6949\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 3.7035e-08 - accuracy: 1.0000 - val_loss: 4.4106 - val_accuracy: 0.6949\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 3.5065e-08 - accuracy: 1.0000 - val_loss: 4.4125 - val_accuracy: 0.6949\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.4997e-08 - accuracy: 1.0000 - val_loss: 4.4144 - val_accuracy: 0.6949\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.5090e-08 - accuracy: 1.0000 - val_loss: 4.4160 - val_accuracy: 0.6864\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.4997e-08 - accuracy: 1.0000 - val_loss: 4.4178 - val_accuracy: 0.6864\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 3.4997e-08 - accuracy: 1.0000 - val_loss: 4.4191 - val_accuracy: 0.6864\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.5144e-08 - accuracy: 1.0000 - val_loss: 4.4205 - val_accuracy: 0.6864\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 3.4352e-08 - accuracy: 1.0000 - val_loss: 4.4222 - val_accuracy: 0.6864\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.4498e-08 - accuracy: 1.0000 - val_loss: 4.4235 - val_accuracy: 0.6864\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 3.4205e-08 - accuracy: 1.0000 - val_loss: 4.4245 - val_accuracy: 0.6864\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 3.4352e-08 - accuracy: 1.0000 - val_loss: 4.4260 - val_accuracy: 0.6864\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 3.4352e-08 - accuracy: 1.0000 - val_loss: 4.4276 - val_accuracy: 0.6864\n",
      "Epoch 884/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 95ms/step - loss: 3.4205e-08 - accuracy: 1.0000 - val_loss: 4.4288 - val_accuracy: 0.6864\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.4283e-08 - accuracy: 1.0000 - val_loss: 4.4292 - val_accuracy: 0.6864\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 3.4352e-08 - accuracy: 1.0000 - val_loss: 4.4307 - val_accuracy: 0.6949\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 3.3529e-08 - accuracy: 1.0000 - val_loss: 4.4324 - val_accuracy: 0.6949\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.3706e-08 - accuracy: 1.0000 - val_loss: 4.4337 - val_accuracy: 0.6949\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 3.3529e-08 - accuracy: 1.0000 - val_loss: 4.4350 - val_accuracy: 0.6949\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.3152e-08 - accuracy: 1.0000 - val_loss: 4.4360 - val_accuracy: 0.6949\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.3299e-08 - accuracy: 1.0000 - val_loss: 4.4371 - val_accuracy: 0.6949\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 3.2942e-08 - accuracy: 1.0000 - val_loss: 4.4381 - val_accuracy: 0.6949\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 3.2712e-08 - accuracy: 1.0000 - val_loss: 4.4390 - val_accuracy: 0.6949\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 3.0971e-08 - accuracy: 1.0000 - val_loss: 4.4396 - val_accuracy: 0.6949\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 3.1115e-08 - accuracy: 1.0000 - val_loss: 4.4413 - val_accuracy: 0.6949\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 3.0538e-08 - accuracy: 1.0000 - val_loss: 4.4429 - val_accuracy: 0.6949\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 2.7687e-08 - accuracy: 1.0000 - val_loss: 4.4439 - val_accuracy: 0.6949\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.7487e-08 - accuracy: 1.0000 - val_loss: 4.4446 - val_accuracy: 0.6949\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 2.7945e-08 - accuracy: 1.0000 - val_loss: 4.4459 - val_accuracy: 0.6949\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 2.7188e-08 - accuracy: 1.0000 - val_loss: 4.4466 - val_accuracy: 0.6949\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 2.8064e-08 - accuracy: 1.0000 - val_loss: 4.4484 - val_accuracy: 0.6949\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 2.7447e-08 - accuracy: 1.0000 - val_loss: 4.4497 - val_accuracy: 0.6949\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 2.6612e-08 - accuracy: 1.0000 - val_loss: 4.4500 - val_accuracy: 0.6949\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 2.7853e-08 - accuracy: 1.0000 - val_loss: 4.4513 - val_accuracy: 0.6949\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 2.7673e-08 - accuracy: 1.0000 - val_loss: 4.4531 - val_accuracy: 0.6949\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 2.6400e-08 - accuracy: 1.0000 - val_loss: 4.4542 - val_accuracy: 0.6949\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 2.6649e-08 - accuracy: 1.0000 - val_loss: 4.4550 - val_accuracy: 0.6949\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.6472e-08 - accuracy: 1.0000 - val_loss: 4.4554 - val_accuracy: 0.6949\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.5895e-08 - accuracy: 1.0000 - val_loss: 4.4553 - val_accuracy: 0.6949\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.7558e-08 - accuracy: 1.0000 - val_loss: 4.4561 - val_accuracy: 0.6949\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.5895e-08 - accuracy: 1.0000 - val_loss: 4.4563 - val_accuracy: 0.6949\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 2.7879e-08 - accuracy: 1.0000 - val_loss: 4.4572 - val_accuracy: 0.6949\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.7226e-08 - accuracy: 1.0000 - val_loss: 4.4589 - val_accuracy: 0.6949\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 2.6804e-08 - accuracy: 1.0000 - val_loss: 4.4595 - val_accuracy: 0.6949\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 2.6649e-08 - accuracy: 1.0000 - val_loss: 4.4602 - val_accuracy: 0.6949\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.5802e-08 - accuracy: 1.0000 - val_loss: 4.4607 - val_accuracy: 0.6949\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.6736e-08 - accuracy: 1.0000 - val_loss: 4.4609 - val_accuracy: 0.6949\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.6662e-08 - accuracy: 1.0000 - val_loss: 4.4631 - val_accuracy: 0.6949\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.6341e-08 - accuracy: 1.0000 - val_loss: 4.4655 - val_accuracy: 0.6949\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 2.5587e-08 - accuracy: 1.0000 - val_loss: 4.4669 - val_accuracy: 0.6949\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 2.5764e-08 - accuracy: 1.0000 - val_loss: 4.4683 - val_accuracy: 0.6949\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.4942e-08 - accuracy: 1.0000 - val_loss: 4.4698 - val_accuracy: 0.6949\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 2.4781e-08 - accuracy: 1.0000 - val_loss: 4.4707 - val_accuracy: 0.6949\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.4958e-08 - accuracy: 1.0000 - val_loss: 4.4723 - val_accuracy: 0.6949\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.4713e-08 - accuracy: 1.0000 - val_loss: 4.4734 - val_accuracy: 0.6949\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.6273e-08 - accuracy: 1.0000 - val_loss: 4.4743 - val_accuracy: 0.6949\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.5173e-08 - accuracy: 1.0000 - val_loss: 4.4756 - val_accuracy: 0.6949\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 2.4713e-08 - accuracy: 1.0000 - val_loss: 4.4763 - val_accuracy: 0.6949\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.5171e-08 - accuracy: 1.0000 - val_loss: 4.4771 - val_accuracy: 0.6949\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.5517e-08 - accuracy: 1.0000 - val_loss: 4.4782 - val_accuracy: 0.6949\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.4417e-08 - accuracy: 1.0000 - val_loss: 4.4775 - val_accuracy: 0.6949\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.4360e-08 - accuracy: 1.0000 - val_loss: 4.4790 - val_accuracy: 0.6949\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.4254e-08 - accuracy: 1.0000 - val_loss: 4.4796 - val_accuracy: 0.6949\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.4256e-08 - accuracy: 1.0000 - val_loss: 4.4805 - val_accuracy: 0.6949\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.2122e-08 - accuracy: 1.0000 - val_loss: 4.4824 - val_accuracy: 0.6949\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 2.4158e-08 - accuracy: 1.0000 - val_loss: 4.4841 - val_accuracy: 0.6949\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.2825e-08 - accuracy: 1.0000 - val_loss: 4.4835 - val_accuracy: 0.6949\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.4017e-08 - accuracy: 1.0000 - val_loss: 4.4856 - val_accuracy: 0.6949\n",
      "Epoch 939/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 93ms/step - loss: 2.2792e-08 - accuracy: 1.0000 - val_loss: 4.4863 - val_accuracy: 0.6949\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.1973e-08 - accuracy: 1.0000 - val_loss: 4.4866 - val_accuracy: 0.6949\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.2509e-08 - accuracy: 1.0000 - val_loss: 4.4890 - val_accuracy: 0.6949\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.2340e-08 - accuracy: 1.0000 - val_loss: 4.4911 - val_accuracy: 0.6949\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.2269e-08 - accuracy: 1.0000 - val_loss: 4.4914 - val_accuracy: 0.6949\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.1912e-08 - accuracy: 1.0000 - val_loss: 4.4920 - val_accuracy: 0.6949\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.0781e-08 - accuracy: 1.0000 - val_loss: 4.4931 - val_accuracy: 0.6949\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.1411e-08 - accuracy: 1.0000 - val_loss: 4.4932 - val_accuracy: 0.6949\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 1.9960e-08 - accuracy: 1.0000 - val_loss: 4.4947 - val_accuracy: 0.6949\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 2.2061e-08 - accuracy: 1.0000 - val_loss: 4.4961 - val_accuracy: 0.6949\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.1505e-08 - accuracy: 1.0000 - val_loss: 4.4972 - val_accuracy: 0.6949\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.0415e-08 - accuracy: 1.0000 - val_loss: 4.4970 - val_accuracy: 0.6949\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.0247e-08 - accuracy: 1.0000 - val_loss: 4.4991 - val_accuracy: 0.6949\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.9651e-08 - accuracy: 1.0000 - val_loss: 4.4993 - val_accuracy: 0.6949\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.9214e-08 - accuracy: 1.0000 - val_loss: 4.4995 - val_accuracy: 0.6949\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 2.2344e-08 - accuracy: 1.0000 - val_loss: 4.5014 - val_accuracy: 0.6949\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 1.8228e-08 - accuracy: 1.0000 - val_loss: 4.5013 - val_accuracy: 0.6949\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.1616e-08 - accuracy: 1.0000 - val_loss: 4.5022 - val_accuracy: 0.6949\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 1.8496e-08 - accuracy: 1.0000 - val_loss: 4.5047 - val_accuracy: 0.6864\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.0410e-08 - accuracy: 1.0000 - val_loss: 4.5040 - val_accuracy: 0.6864\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 1.8850e-08 - accuracy: 1.0000 - val_loss: 4.5060 - val_accuracy: 0.6864\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.9222e-08 - accuracy: 1.0000 - val_loss: 4.5072 - val_accuracy: 0.6864\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.8877e-08 - accuracy: 1.0000 - val_loss: 4.5067 - val_accuracy: 0.6864\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 1.9039e-08 - accuracy: 1.0000 - val_loss: 4.5065 - val_accuracy: 0.6864\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.8219e-08 - accuracy: 1.0000 - val_loss: 4.5085 - val_accuracy: 0.6864\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.7954e-08 - accuracy: 1.0000 - val_loss: 4.5089 - val_accuracy: 0.6864\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.8018e-08 - accuracy: 1.0000 - val_loss: 4.5093 - val_accuracy: 0.6864\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.8911e-08 - accuracy: 1.0000 - val_loss: 4.5100 - val_accuracy: 0.6864\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.9033e-08 - accuracy: 1.0000 - val_loss: 4.5120 - val_accuracy: 0.6864\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.9623e-08 - accuracy: 1.0000 - val_loss: 4.5110 - val_accuracy: 0.6864\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 1.7735e-08 - accuracy: 1.0000 - val_loss: 4.5139 - val_accuracy: 0.6864\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.9315e-08 - accuracy: 1.0000 - val_loss: 4.5128 - val_accuracy: 0.6864\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 1.8523e-08 - accuracy: 1.0000 - val_loss: 4.5144 - val_accuracy: 0.6864\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.7667e-08 - accuracy: 1.0000 - val_loss: 4.5133 - val_accuracy: 0.6864\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.6593e-08 - accuracy: 1.0000 - val_loss: 4.5143 - val_accuracy: 0.6864\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 1.8459e-08 - accuracy: 1.0000 - val_loss: 4.5150 - val_accuracy: 0.6864\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.8440e-08 - accuracy: 1.0000 - val_loss: 4.5168 - val_accuracy: 0.6864\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.7598e-08 - accuracy: 1.0000 - val_loss: 4.5168 - val_accuracy: 0.6864\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 1.7883e-08 - accuracy: 1.0000 - val_loss: 4.5171 - val_accuracy: 0.6864\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.7673e-08 - accuracy: 1.0000 - val_loss: 4.5166 - val_accuracy: 0.6864\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 1.8381e-08 - accuracy: 1.0000 - val_loss: 4.5163 - val_accuracy: 0.6864\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.7449e-08 - accuracy: 1.0000 - val_loss: 4.5190 - val_accuracy: 0.6864\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.9386e-08 - accuracy: 1.0000 - val_loss: 4.5181 - val_accuracy: 0.6864\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 1.6508e-08 - accuracy: 1.0000 - val_loss: 4.5193 - val_accuracy: 0.6864\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.7556e-08 - accuracy: 1.0000 - val_loss: 4.5200 - val_accuracy: 0.6864\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.7603e-08 - accuracy: 1.0000 - val_loss: 4.5217 - val_accuracy: 0.6864\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.7585e-08 - accuracy: 1.0000 - val_loss: 4.5203 - val_accuracy: 0.6864\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.6405e-08 - accuracy: 1.0000 - val_loss: 4.5230 - val_accuracy: 0.6864\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 1.6583e-08 - accuracy: 1.0000 - val_loss: 4.5238 - val_accuracy: 0.6864\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.6089e-08 - accuracy: 1.0000 - val_loss: 4.5246 - val_accuracy: 0.6864\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 1.7991e-08 - accuracy: 1.0000 - val_loss: 4.5251 - val_accuracy: 0.6864\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 1.7929e-08 - accuracy: 1.0000 - val_loss: 4.5256 - val_accuracy: 0.6864\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.7201e-08 - accuracy: 1.0000 - val_loss: 4.5250 - val_accuracy: 0.6864\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 1.7172e-08 - accuracy: 1.0000 - val_loss: 4.5269 - val_accuracy: 0.6864\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.4771e-08 - accuracy: 1.0000 - val_loss: 4.5291 - val_accuracy: 0.6864\n",
      "Epoch 994/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 93ms/step - loss: 1.7705e-08 - accuracy: 1.0000 - val_loss: 4.5315 - val_accuracy: 0.6864\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.6495e-08 - accuracy: 1.0000 - val_loss: 4.5303 - val_accuracy: 0.6864\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 1.5344e-08 - accuracy: 1.0000 - val_loss: 4.5299 - val_accuracy: 0.6864\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.5657e-08 - accuracy: 1.0000 - val_loss: 4.5303 - val_accuracy: 0.6864\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.4407e-08 - accuracy: 1.0000 - val_loss: 4.5336 - val_accuracy: 0.6864\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.7012e-08 - accuracy: 1.0000 - val_loss: 4.5333 - val_accuracy: 0.6864\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.3865e-08 - accuracy: 1.0000 - val_loss: 4.5333 - val_accuracy: 0.6864\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  batch_size=batch_size,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")\n",
    "\n",
    "hdf5_file = \"./model/improved_model_1.hdf5\"\n",
    "model.save_weights(hdf5_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MEtT9YGjSAOK"
   },
   "source": [
    "참고: `model.fit`을 사용하는 대신 사용자 정의 훈련 루프를 작성할 수도 있습니다. 자세한 내용은 이 [튜토리얼](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch)을 참조하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaW4wx5L7hrZ"
   },
   "source": [
    "검증 정확성이 훈련 정확성에 비해 낮으므로 모델이 과대적합되었음을 알 수 있습니다. 이 [튜토리얼](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit)에서 과대적합 및 축소 방법에 대해 자세히 알아볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "catfish_url = \"data:image/jpeg;base64,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\"\n",
    "catfish_path = tf.keras.utils.get_file('catfish', origin=catfish_url)\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img(\n",
    "    catfish_path, target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n",
    "\n",
    "print(class_names[np.argmax(score)])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# carp_url = \"https://lh3.googleusercontent.com/proxy/eMuxcYh_Qyqq-RVHFsNXt-FnETiNVc4KQIo2Fuax1vGbYpJWEeHUTun00ujtFl3rPjRR6nHuWwVmHCAAeEwNuuRQWU8h8y_ClLv9L4cNiAFWpowKhdTxjXPeTQ_aWEy06EgIYolNM70jngdT79DkMev_EjQ\"\n",
    "carp_url = \"data:image/jpeg;base64,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\"\n",
    "carp_path = tf.keras.utils.get_file('carp', origin=carp_url)\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img(\n",
    "    carp_path, target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mandarin_url = \"http://fish.darakwon.co.kr/fdata/fish/contents/info/images/20110427475B.jpg\"\n",
    "mandarin_path = tf.keras.utils.get_file('mandarin', origin=mandarin_url)\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img(\n",
    "    mandarin_path, target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bass_url = \"data:image/jpeg;base64,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\"\n",
    "bass_path = tf.keras.utils.get_file('bass', origin=bass_url)\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img(\n",
    "    bass_path, target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "carp_url = \"https://i.ytimg.com/vi/KlKg1LRnsMo/maxresdefault.jpg\"\n",
    "carp_path = tf.keras.utils.get_file('carp', origin=carp_url)\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img(\n",
    "    carp_path, target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "images.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
